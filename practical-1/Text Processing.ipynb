{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae74b4c",
   "metadata": {},
   "source": [
    "# **Text Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9417a471-a06c-43f0-987a-5a9d7b985145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7caa88",
   "metadata": {},
   "source": [
    "## **SECTION 0: Preparing Dataset for Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6bed7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"When life gives you lemons, make lemonade! ðŸ™‚\",\n",
    "    \"She bought 2 lemons for $1 at Maven Market.\",\n",
    "    \"A dozen lemons will make a gallon of lemonade. [AllRecipes]\",\n",
    "    \"lemon, lemon, lemons, lemon, lemon, lemons\",\n",
    "    \"He's running to the market to get a lemon â€” there's a great sale today.\",\n",
    "    \"Does Maven Market carry Eureka lemons or Meyer lemons?\",\n",
    "    \"An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]\",\n",
    "    \"iced tea is my favorite\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4bd570af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When life gives you lemons, make lemonade! ðŸ™‚',\n",
       " 'She bought 2 lemons for $1 at Maven Market.',\n",
       " 'A dozen lemons will make a gallon of lemonade. [AllRecipes]',\n",
       " 'lemon, lemon, lemons, lemon, lemon, lemons',\n",
       " \"He's running to the market to get a lemon â€” there's a great sale today.\",\n",
       " 'Does Maven Market carry Eureka lemons or Meyer lemons?',\n",
       " 'An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]',\n",
       " 'iced tea is my favorite']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fa30883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Sentence\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚\n",
       "1                              She bought 2 lemons for $1 at Maven Market.\n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]\n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons\n",
       "4  He's running to the market to get a lemon â€” there's a great sale today.\n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?\n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]\n",
       "7                                                  iced tea is my favorite"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting list to dataframe\n",
    "data_df = pd.DataFrame(data, columns=['Sentence'])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff00b0",
   "metadata": {},
   "source": [
    "*Purpose: Transforms the list into Dataframe for better analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5add0e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Sentence\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚\n",
       "1                              She bought 2 lemons for $1 at Maven Market.\n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]\n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons\n",
       "4  He's running to the market to get a lemon â€” there's a great sale today.\n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?\n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]\n",
       "7                                                  iced tea is my favorite"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display full text in DataFrame\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c8f41",
   "metadata": {},
   "source": [
    "*Purpose: Configure pandas to display complete sentence content without truncation, which is essential for preprocessing*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb059342",
   "metadata": {},
   "source": [
    "## **SECTION 1: Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd6dc1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Sentence\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚\n",
       "1                              She bought 2 lemons for $1 at Maven Market.\n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]\n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons\n",
       "4  He's running to the market to get a lemon â€” there's a great sale today.\n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?\n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]\n",
       "7                                                  iced tea is my favorite"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the original data\n",
    "spacy_df = data_df.copy()\n",
    "spacy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764ead6",
   "metadata": {},
   "source": [
    "*Purpose: Its helps to preserve our original data*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa308606",
   "metadata": {},
   "source": [
    "### **1.1 Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b7bc831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "      <td>when life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "      <td>she bought 2 lemons for $1 at maven market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "      <td>a dozen lemons will make a gallon of lemonade. [allrecipes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "      <td>he's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "      <td>does maven market carry eureka lemons or meyer lemons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "      <td>an arnold palmer is half lemonade, half iced tea. [wikipedia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Sentence  \\\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚   \n",
       "1                              She bought 2 lemons for $1 at Maven Market.   \n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]   \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons   \n",
       "4  He's running to the market to get a lemon â€” there's a great sale today.   \n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?   \n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]   \n",
       "7                                                  iced tea is my favorite   \n",
       "\n",
       "                                                            clean_sentence  \n",
       "0                             when life gives you lemons, make lemonade! ðŸ™‚  \n",
       "1                              she bought 2 lemons for $1 at maven market.  \n",
       "2              a dozen lemons will make a gallon of lemonade. [allrecipes]  \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons  \n",
       "4  he's running to the market to get a lemon â€” there's a great sale today.  \n",
       "5                   does maven market carry eureka lemons or meyer lemons?  \n",
       "6            an arnold palmer is half lemonade, half iced tea. [wikipedia]  \n",
       "7                                                  iced tea is my favorite  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercasing the text for consistency and store the results in a new column called 'clean_sentence'\n",
    "spacy_df['clean_sentence'] = spacy_df['Sentence'].str.lower()\n",
    "spacy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7313ebc",
   "metadata": {},
   "source": [
    "### **1.2 Text Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3ca1aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "      <td>when life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "      <td>she bought 2 lemons for $1 at maven market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "      <td>a dozen lemons will make a gallon of lemonade. [allrecipes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "      <td>he's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "      <td>does maven market carry eureka lemons or meyer lemons?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "      <td>an arnold palmer is half lemonade, half iced tea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Sentence  \\\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚   \n",
       "1                              She bought 2 lemons for $1 at Maven Market.   \n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]   \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons   \n",
       "4  He's running to the market to get a lemon â€” there's a great sale today.   \n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?   \n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]   \n",
       "7                                                  iced tea is my favorite   \n",
       "\n",
       "                                                            clean_sentence  \n",
       "0                             when life gives you lemons, make lemonade! ðŸ™‚  \n",
       "1                              she bought 2 lemons for $1 at maven market.  \n",
       "2              a dozen lemons will make a gallon of lemonade. [allrecipes]  \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons  \n",
       "4  he's running to the market to get a lemon â€” there's a great sale today.  \n",
       "5                   does maven market carry eureka lemons or meyer lemons?  \n",
       "6                       an arnold palmer is half lemonade, half iced tea.   \n",
       "7                                                  iced tea is my favorite  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing special characters such as references and citations\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace('[wikipedia]', '')\n",
    "spacy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8847847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When life gives you lemons, make lemonade! ðŸ™‚</td>\n",
       "      <td>when life gives you lemons make lemonade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She bought 2 lemons for $1 at Maven Market.</td>\n",
       "      <td>she bought 2 lemons for 1 at maven market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dozen lemons will make a gallon of lemonade. [AllRecipes]</td>\n",
       "      <td>a dozen lemons will make a gallon of lemonade allrecipes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon, lemon, lemons, lemon, lemon, lemons</td>\n",
       "      <td>lemon lemon lemons lemon lemon lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He's running to the market to get a lemon â€” there's a great sale today.</td>\n",
       "      <td>he s running to the market to get a lemon there s a great sale today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Does Maven Market carry Eureka lemons or Meyer lemons?</td>\n",
       "      <td>does maven market carry eureka lemons or meyer lemons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]</td>\n",
       "      <td>an arnold palmer is half lemonade half iced tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iced tea is my favorite</td>\n",
       "      <td>iced tea is my favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Sentence  \\\n",
       "0                             When life gives you lemons, make lemonade! ðŸ™‚   \n",
       "1                              She bought 2 lemons for $1 at Maven Market.   \n",
       "2              A dozen lemons will make a gallon of lemonade. [AllRecipes]   \n",
       "3                               lemon, lemon, lemons, lemon, lemon, lemons   \n",
       "4  He's running to the market to get a lemon â€” there's a great sale today.   \n",
       "5                   Does Maven Market carry Eureka lemons or Meyer lemons?   \n",
       "6            An Arnold Palmer is half lemonade, half iced tea. [Wikipedia]   \n",
       "7                                                  iced tea is my favorite   \n",
       "\n",
       "                                                         clean_sentence  \n",
       "0                              when life gives you lemons make lemonade  \n",
       "1                             she bought 2 lemons for 1 at maven market  \n",
       "2              a dozen lemons will make a gallon of lemonade allrecipes  \n",
       "3                                 lemon lemon lemons lemon lemon lemons  \n",
       "4  he s running to the market to get a lemon there s a great sale today  \n",
       "5                 does maven market carry eureka lemons or meyer lemons  \n",
       "6                       an arnold palmer is half lemonade half iced tea  \n",
       "7                                               iced tea is my favorite  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Advanced cleaning using regex\n",
    "\n",
    "combined = r'https?://\\S+|www\\.\\S+|<.*?>|\\S+@\\S+\\.\\S+|@\\w+|#\\w+|[^A-Za-z0-9\\s]'\n",
    "\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace(combined, ' ', regex=True)\n",
    "\n",
    "spacy_df['clean_sentence'] = spacy_df['clean_sentence'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "spacy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349e7e6",
   "metadata": {},
   "source": [
    "*Purpose: Use regular expressions to remove URLs, email addresses, social media handles, and non-alphanumeric characters*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d0b047",
   "metadata": {},
   "source": [
    "### **1.3 Advanced Text Processing with spaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "388059d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84af018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained pipeline\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b6426",
   "metadata": {},
   "source": [
    "### **1.3.1 Tokenization**\n",
    "\n",
    "**Tokenization** splits text into individual units (tokens) such as words, punctuation marks, or numbers. Modern tokenizers handle complex cases like contractions, compound words, and special characters intelligently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eeeca388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[when, life, gives, you, lemons, make, lemonade]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a spaCy doc object from the first sentence\n",
    "doc = nlp(spacy_df.loc[0, 'clean_sentence'])\n",
    "\n",
    "# Extract tokens as text strings\n",
    "[token.text for token in doc]\n",
    "# Output: ['when', 'life', 'gives', 'you', 'lemons', 'make', 'lemonade']\n",
    "\n",
    "# Extract tokens as spaCy objects (with linguistic attributes)\n",
    "[token for token in doc]\n",
    "# Output: [when, life, gives, you, lemons, make, lemonade]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96add9da",
   "metadata": {},
   "source": [
    "### **1.3.2 Lemmatization**\n",
    "\n",
    "**Lemmatization** reduces words to their base or root form (lemma) using linguistic knowledge. Unlike stemming, which simply removes suffixes, lemmatization considers the word's part of speech and meaning to find the correct root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef44c84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when', 'life', 'give', 'you', 'lemon', 'make', 'lemonade']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extract lemmatized forms\n",
    "\n",
    "[token.lemma_ for token in doc]\n",
    "\n",
    "# Output: ['when', 'life', 'give', 'you', 'lemon', 'make', 'lemonade']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50749abd",
   "metadata": {},
   "source": [
    "### **1.3.3 Stop Words Removal**\n",
    "\n",
    "**Stop words** are common words that carry little semantic meaning and are often filtered out to focus on more meaningful content. Examples include \"the\", \"and\", \"is\", \"in\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b920199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words: 326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'life give lemon lemonade'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# View all English stop words in spaCy\n",
    "\n",
    "list(nlp.Defaults.stop_words)\n",
    "\n",
    "print(f\"Total stop words: {len(list(nlp.Defaults.stop_words))}\") # 326 stop words\n",
    "\n",
    "\n",
    "\n",
    "# Remove stop words\n",
    "\n",
    "[token for token in doc if  not token.is_stop]\n",
    "\n",
    "# Output: [life, gives, lemons, lemonade]\n",
    "\n",
    "\n",
    "\n",
    "# Combine lemmatization and stop word removal\n",
    "\n",
    "[token.lemma_ for token in doc if  not token.is_stop]\n",
    "\n",
    "# Output: ['life', 'give', 'lemon', 'lemonade']\n",
    "\n",
    "\n",
    "\n",
    "# Convert back to sentence format\n",
    "\n",
    "norm = [token.lemma_ for token in doc if  not token.is_stop]\n",
    "\n",
    "' '.join(norm) # Output: 'life give lemon lemonade'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f3076",
   "metadata": {},
   "source": [
    "## **Section 2: Creating Reusable Functions**\n",
    "\n",
    "Creating modular, reusable functions is essential for maintainable code and consistent preprocessing across different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8da0f3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       life give lemon lemonade\n",
       "1                     buy 2 lemon 1 maven market\n",
       "2          dozen lemon gallon lemonade allrecipe\n",
       "3            lemon lemon lemon lemon lemon lemon\n",
       "4          s run market lemon s great sale today\n",
       "5    maven market carry eureka lemon meyer lemon\n",
       "6       arnold palmer half lemonade half ice tea\n",
       "7                               ice tea favorite\n",
       "Name: clean_sentence, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Function for lemmatization and stop word removal\n",
    "\n",
    "def  token_lemma_stopw(text):\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    output = [token.lemma_ for token in doc if  not token.is_stop]\n",
    "\n",
    "    return  ' '.join(output)\n",
    "\n",
    "\n",
    "\n",
    "# Apply to entire dataset\n",
    "\n",
    "spacy_df.clean_sentence.apply(token_lemma_stopw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98aaf5c",
   "metadata": {},
   "source": [
    "## **Section 3: Complete NLP Pipeline**\n",
    "\n",
    "An **NLP pipeline** combines multiple preprocessing steps into a single, streamlined workflow. This approach ensures consistency and makes it easy to apply the same transformations to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0456018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def  lower_replace(series):\n",
    "\n",
    "    output = series.str.lower()\n",
    "\n",
    "    combined = r'https?://\\S+|www\\.\\S+|<.*?>|\\S+@\\S+\\.\\S+|@\\w+|#\\w+|[^A-Za-z0-9\\s]'\n",
    "\n",
    "    output = output.str.replace(combined, ' ', regex=True)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def  nlp_pipeline(series):\n",
    "\n",
    "    output = lower_replace(series)\n",
    "\n",
    "    output = output.apply(token_lemma_stopw)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# Apply complete pipeline\n",
    "\n",
    "cleaned_text = nlp_pipeline(data_df.Sentence)\n",
    "\n",
    "\n",
    "# Save processed data for future use\n",
    "\n",
    "pd.to_pickle(cleaned_text, 'preprocessed_text.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0a778",
   "metadata": {},
   "source": [
    "## **Section 4: Word Representation (Vectorization)**\n",
    "\n",
    "**Vectorization** converts preprocessed text into numerical representations that machine learning algorithms can process. Text must be transformed into vectors (arrays of numbers) because algorithms cannot directly work with text strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a6702",
   "metadata": {},
   "source": [
    "### **Count Vectorization (Bag of Words)**\n",
    "\n",
    "**Count Vectorization** creates a matrix where each row represents a document and each column represents a unique word in the corpus. Cell values indicate how many times each word appears in each document. This approach ignores word order but captures word frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "700dd5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./lib/python3.10/site-packages (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allrecipe</th>\n",
       "      <th>arnold</th>\n",
       "      <th>buy</th>\n",
       "      <th>carry</th>\n",
       "      <th>dozen</th>\n",
       "      <th>eureka</th>\n",
       "      <th>favorite</th>\n",
       "      <th>gallon</th>\n",
       "      <th>give</th>\n",
       "      <th>great</th>\n",
       "      <th>...</th>\n",
       "      <th>life</th>\n",
       "      <th>market</th>\n",
       "      <th>maven</th>\n",
       "      <th>meyer</th>\n",
       "      <th>palmer</th>\n",
       "      <th>run</th>\n",
       "      <th>sale</th>\n",
       "      <th>tea</th>\n",
       "      <th>today</th>\n",
       "      <th>wikipedia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   allrecipe  arnold  buy  carry  dozen  eureka  favorite  gallon  give  \\\n",
       "0          0       0    0      0      0       0         0       0     1   \n",
       "1          0       0    1      0      0       0         0       0     0   \n",
       "2          1       0    0      0      1       0         0       1     0   \n",
       "3          0       0    0      0      0       0         0       0     0   \n",
       "4          0       0    0      0      0       0         0       0     0   \n",
       "5          0       0    0      1      0       1         0       0     0   \n",
       "6          0       1    0      0      0       0         0       0     0   \n",
       "7          0       0    0      0      0       0         1       0     0   \n",
       "\n",
       "   great  ...  life  market  maven  meyer  palmer  run  sale  tea  today  \\\n",
       "0      0  ...     1       0      0      0       0    0     0    0      0   \n",
       "1      0  ...     0       1      1      0       0    0     0    0      0   \n",
       "2      0  ...     0       0      0      0       0    0     0    0      0   \n",
       "3      0  ...     0       0      0      0       0    0     0    0      0   \n",
       "4      1  ...     0       1      0      0       0    1     1    0      1   \n",
       "5      0  ...     0       1      1      1       0    0     0    0      0   \n",
       "6      0  ...     0       0      0      0       1    0     0    1      0   \n",
       "7      0  ...     0       0      0      0       0    0     0    1      0   \n",
       "\n",
       "   wikipedia  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          1  \n",
       "7          0  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%pip install scikit-learn\n",
    "\n",
    "# Load preprocessed data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "series = pd.read_pickle('preprocessed_text.pkl')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create Count Vectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(series)\n",
    "\n",
    "# Convert to DataFrame for visualization\n",
    "\n",
    "pd.DataFrame(bow.toarray(), columns=cv.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06067bff",
   "metadata": {},
   "source": [
    "### **Advanced Count Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2089e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count Vectorizer with filtering\n",
    "\n",
    "cv1 = CountVectorizer(\n",
    "\n",
    "stop_words='english', # Remove English stop words\n",
    "\n",
    "ngram_range=(1,1), # Use only single words (unigrams)\n",
    "\n",
    "min_df=2  # Include words that appear in at least 2 documents\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "bow1 = cv1.fit_transform(series)\n",
    "\n",
    "bow1_df = pd.DataFrame(bow1.toarray(), columns=cv1.get_feature_names_out())\n",
    "\n",
    "\n",
    "\n",
    "# Calculate term frequencies\n",
    "\n",
    "term_freq = bow1_df.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087bde5",
   "metadata": {},
   "source": [
    "## **Section 5: TF-IDF (Term Frequency-Inverse Document Frequency)**\n",
    "\n",
    "**TF-IDF** addresses a key limitation of simple count vectorization by considering both term frequency (how often a word appears in a document) and inverse document frequency (how rare the word is across the entire corpus).\n",
    "\n",
    "- **Formula:**  \n",
    "  $$ TF\\text{-}IDF = TF \\times IDF $$\n",
    "\n",
    "- **TF (Term Frequency):**  \n",
    "  \\[\n",
    "  TF = \\frac{\\text{Number of times word appears in document}}{\\text{Total words in document}}\n",
    "  \\]\n",
    "\n",
    "- **IDF (Inverse Document Frequency):**  \n",
    "  \\[\n",
    "  IDF = \\log \\left( \\frac{\\text{Total documents}}{\\text{Documents containing the word}} \\right)\n",
    "  \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e7e349a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Basic TF-IDF vectorization\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "\n",
    "tvidf = tv.fit_transform(series)\n",
    "\n",
    "tvidf_df = pd.DataFrame(tvidf.toarray(), columns=tv.get_feature_names_out())\n",
    "\n",
    "\n",
    "\n",
    "# TF-IDF with filtering\n",
    "\n",
    "tv1 = TfidfVectorizer(min_df=2) # Words must appear in at least 2 documents\n",
    "\n",
    "tvidf1 = tv1.fit_transform(series)\n",
    "\n",
    "tvidf1_df = pd.DataFrame(tvidf1.toarray(), columns=tv1.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed880c8",
   "metadata": {},
   "source": [
    "*Note:* \n",
    "- Values closer to 1 indicate highly distinctive words\n",
    "\n",
    "- Values closer to 0 indicate either common words or absent words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2afa5",
   "metadata": {},
   "source": [
    "### **N-gram Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "faa688ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemon                 1.583310\n",
       "lemon lemon           0.857624\n",
       "market                0.767950\n",
       "lemonade              0.743321\n",
       "ice tea               0.625522\n",
       "ice                   0.625522\n",
       "tea                   0.625522\n",
       "maven                 0.621858\n",
       "maven market          0.621858\n",
       "half                  0.505881\n",
       "favorite              0.493436\n",
       "tea favorite          0.493436\n",
       "lemon maven           0.439482\n",
       "buy                   0.439482\n",
       "buy lemon             0.439482\n",
       "give lemon            0.416207\n",
       "life                  0.416207\n",
       "lemon lemonade        0.416207\n",
       "give                  0.416207\n",
       "life give             0.416207\n",
       "gallon lemonade       0.358685\n",
       "dozen lemon           0.358685\n",
       "allrecipe             0.358685\n",
       "dozen                 0.358685\n",
       "gallon                0.358685\n",
       "lemonade allrecipe    0.358685\n",
       "lemon gallon          0.358685\n",
       "sale today            0.319884\n",
       "today                 0.319884\n",
       "great sale            0.319884\n",
       "great                 0.319884\n",
       "market lemon          0.319884\n",
       "lemon great           0.319884\n",
       "run market            0.319884\n",
       "sale                  0.319884\n",
       "run                   0.319884\n",
       "eureka                0.302522\n",
       "meyer lemon           0.302522\n",
       "market carry          0.302522\n",
       "meyer                 0.302522\n",
       "lemon meyer           0.302522\n",
       "carry                 0.302522\n",
       "carry eureka          0.302522\n",
       "eureka lemon          0.302522\n",
       "arnold                0.252941\n",
       "half lemonade         0.252941\n",
       "half ice              0.252941\n",
       "arnold palmer         0.252941\n",
       "lemonade half         0.252941\n",
       "palmer half           0.252941\n",
       "palmer                0.252941\n",
       "tea wikipedia         0.252941\n",
       "wikipedia             0.252941\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Bigram TF-IDF (pairs of consecutive words)\n",
    "\n",
    "tv2 = TfidfVectorizer(ngram_range=(1,2)) # Include both unigrams and bigrams\n",
    "\n",
    "tvidf2 = tv2.fit_transform(series)\n",
    "\n",
    "tvidf2_df = pd.DataFrame(tvidf2.toarray(), columns=tv2.get_feature_names_out())\n",
    "\n",
    "\n",
    "\n",
    "# Analyze feature importance\n",
    "\n",
    "tvidf2_df.sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eecb9a8",
   "metadata": {},
   "source": [
    "*Purpose:*\n",
    "\n",
    "- Capture phrase-level information with bigrams\n",
    "\n",
    "- Examples: \"arnold palmer\", \"buy lemon\", \"ice tea\"\n",
    "\n",
    "- Preserve some context that unigrams lose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
