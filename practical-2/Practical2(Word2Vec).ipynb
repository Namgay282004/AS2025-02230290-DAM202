{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqTAnzNHCJvM"
      },
      "source": [
        "## **0. Environment Setups**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1b_Iu3fBeVv",
        "outputId": "e68e6a01-df5a-4cf6-91b8-978a9df8dc61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "# Path to your working directory\n",
        "ROOT = \"/content/drive/MyDrive/DAM202-Practicals\"\n",
        "import os\n",
        "os.chdir(ROOT)\n",
        "\n",
        "# Install required packages\n",
        "!pip install gensim nltk numpy scipy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o0G6sPjCGDv",
        "outputId": "d0060283-5b4e-4558-dba8-6436d1db98b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Word2Vec.ipynb',\n",
              " 'alice.txt',\n",
              " 'Practical2(Word2Vec).ipynb',\n",
              " 'my_word2vec_model.model']"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoG7erNeDHgJ"
      },
      "source": [
        "## **1. Code Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvM4rsEiDQcR"
      },
      "source": [
        "### **1.1 Data Collection and Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4IUwwDcDlFA",
        "outputId": "465781b7-4eb5-45e9-cea0-e5ad1c9504ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 3599 text documents\n",
            "Sample texts: [\"                ALICE'S ADVENTURES IN WONDERLAND\\n\", '\\n', '                          Lewis Carroll\\n']\n"
          ]
        }
      ],
      "source": [
        "# Load your text data\n",
        "with open('alice.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.readlines()\n",
        "\n",
        "# Check initial data\n",
        "print(f\"Loaded {len(texts)} text documents\")\n",
        "print(\"Sample texts:\", texts[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neTqec-oDpM_"
      },
      "source": [
        "### **1.2 Data Quality Assessment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m3RKmgcDwjU",
        "outputId": "f09834a1-799f-43fc-ae31-a31b843b8ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total documents: 3,599\n",
            "Vocabulary size: 4,950\n",
            "Unique Words: {'middle.', 'say.', 'baked', \"execution.'\", 'loudly', 'home;', 'execution--once', 'nervous', 'ever:', \"bite,'\", \"`i--i'm\", \"lower,'\", '`you', \"bread-knife.'\", 'him,)', 'lasted.)', 'sheep-', 'them--and', 'adding,', 'pope,', 'executioner,', 'using', 'disagree', 'otherwise', 'gryphon,', 'bit,', 'then--she', 'going', 'helped', '`hm!', 'stop', 'sage,', 'ourselves,', 'seldom', \"cakes,'\", \"mouse!')\", '\"poison\"', 'account', \"nothing.'\", 'banks,', 'somebody,', 'up:', 'labelled', 'itself,', 'gardeners', 'piece', 'gallons', 'bristling', 'tremulous', 'worried.', 'station.)', 'corner--no,', 'choice,', 'now!', 'day', 'morning', 'bit', 'himself:', 'further:', 'tunnel', 'woke', '`exactly', 'marked', 'interrupted:', 'bill,', \"dance,'\", \"with?'\", 'thunder,', 'contradicted', 'court,', 'heard', 'merrily', 'appearing', 'am!', 'cards,', 'mushroom', 'pop', \"somewhere,'\", 'juror', 'flamingo,', 'creatures,', 'remarked:', 'doubt', 'twist', 'sizes', 'after-time,', 'childhood:', 'decidedly,', \"finished.'\", 'therefore', \"they've\", 'day:', \"hand,'\", '`fury', 'moderate.', 'mostly', 'around', 'growl', 'which),', \"course.'\", 'let', 'minute', 'business', 'room!', 'severity;', 'knock,', '`very', \"up,'\", 'when', 'bill', 'nothing.', 'frightened', 'hastily,', 'speak.', 'hare,)', \"liked.'\", 'reality--the', 'stole', \"thimble,'\", 'pocket,', 'trouble', \"home?'\", 'stockings', \"whatever,'\", \"wouldn't\", 'lessons:', 'turtle:', \"these?'\", 'iii', \"enough!'\", 'wrong,', 'ending', 'rule', 'shrinking', 'thought.', \"would,'\", 'or', 'rudeness', 'front', '(she', 'executed', \"didn't\", 'door.', '`whenever', 'desperately:', 'pegs.', 'which', 'fetch', \"you?'\", 'work,', 'wondering', 'savage', 'pleased', 'still', \"ma!'\", \"sell,'\", \"she'll\", 'seem,', \"time!'\", 'proper', 'found:', 'ear,', 'different,', 'hearing', 'size,', 'remarks', 'tail;', 'kindly', 'your', '`--mystery,', 'cut', \"do,'\", \"about,'\", 'matter', \"this,'\", 'sure', 'shifting', 'gone,', 'shrimp', 'denial;', 'shrieks,', 'grey', 'wood.', \"off,'\", 'sour--and', 'altogether', 'interesting.', \"`you're\", \"two!'\", '`allow', 'funny', 'since', 'diamonds,', 'paused', 'places--', 'twelve,', 'soldiers,', \"hedge!'\", 'little.', 'waters', \"far,'\", 'modern,', 'could!', 'addressed', 'caterpillar;', 'flamingoes,', 'hedgehogs,', 'later.', 'others.', \"something!'\", 'sneezes;', 'hard', 'games', \"queen?'\", \"rabbit's--`pat!\", 'knee.', 'lefthand', \"said--'\", 'trumpet,', \"evidence,'\", 'thinking', 'interesting', 'rock,', 'alice)--', 'alternately', 'sighed', 'timid', 'yawning', \"you're\", '`well,', 'arms', 'down!', \"book,'\", 'lizard)', 'afraid,', '`never', 'miss,', 'remark,', 'pray,', 'walking', 'law:', 'put', 'muttered', 'reading,', 'much,', 'oldest', \"experiment?'\", 'aloud;', 'jumping', 'it!--that', 'advisable', 'faint', 'sitting', 'people!', 'o', \"queen's\", \"fellow!'\", 'swim', 'course--', 'climb', \"dinah!'\", '`--well', '`he', 'though', 'consider', 'rises', 'so', 'conduct', \"jury--'\", 'dinn', 'king:', \"child?'\", 'straightened', 'lory.', 'character,', 'written', \"caterpillar's\", \"didn't!'\", '\"twinkle,', '`when', 'fills', 'thimble,', \"alice!'\", 'dream:--', \"that?'\", 'wish', 'hatter;', 'either,', 'herself.', '(and', '`dear,', \"draw,'\", 'hookah', \"business?'\", \"i,'\", \"savage!'\", 'business,', \"wonder?'\", 'asked.', 'them.', 'save', \"sir'\", 'general', \"rate,'\", 'eat', 'remain', 'northumbria--\"\\'', 'depends', 'enough', 'morsel', 'insolence', 'branches,', 'down,', 'squeaking', 'the', 'rat-hole:', 'her,', 'e--e--evening,', \"footman's\", 'would,', 'way--never', 'fading', 'burnt,', 'further', 'done,', 'march,', 'politely', 'pool?', 'truthful', 'swallow', \"mostly,'\", '`\"miss', 'impatiently:', 'advise', 'puzzled,', 'that,', 'duchess;', 'jaws', 'quick,', 'stop.', 'growing', 'question;', 'purring', 'blows', 'grunted,', 'head', 'london', 'teapot.', 'ink,', 'might', \"is!'\", '`ou', 'agree', \"people,'\", 'caterpillar.', 'dreadfully', 'boy--and', 'here?', 'stoop', 'particular--', 'pattern', 'cakes,', 'obstacle', 'wriggling', 'carried', 'seem', 'court.', \"jurors.'\", 'to,', 'occurred', 'rose', 'wonderland', 'porpoise', 'obliged', \"certainly,'\", 'loud,', 'sneezing', \"choice!'\", \"trouble!'\", 'tucked', 'holding,', 'grinned', 'terms', 'tureen!', 'feet,', \"`never!'\", '\"purpose\"?\\'', 'remarking', \"off?'\", 'listeners', \"myself,'\", 'inside,', 'spoke', 'turn-up', 'brown', 'forget', 'off,', 'happening.', 'hopeless', '\"coming', 'swim--\"', 'see', '`where', 'swim,', 'carroll', 'caterpillar', 'heels', \"down,'\", 'kiss', 'jumped', \"she's\", \"`shan't,'\", 'fear', 'eating', 'think!', \"growling,'\", 'finger,', 'beloved', 'drink', 'owl,', 'great', \"enough,'\", 'newspapers,', 'led', \"remarks,'\", 'lives', 'room', 'tongue', 'porpoise?\"\\'', 'canvas', 'joys,', 'side.', 'grins', 'smoke', '`eat', \"treacle,'\", 'cheap', \"know?'\", \"on?'\", 'ever;', 'mine', 'away', \"verse.'\", \"me'\", 'remark.', 'muttering', 'eyes.--`tell', 'sixpence.', 'calling', 'smiled', 'minded', 'wretched', \"`stolen!'\", \"it'll\", 'accident,', '`your', 'timidly:', 'sleep\"', 'pointed', 'him', 'decidedly', \"mayn't\", 'this),', 'sounds', 'sneezing,', 'fish', 'ours', 'dears!', 'executioner', 'driest', \"altered.'\", '`is', \"never!'\", 'afterwards,', \"isn't,'\", 'ago', 'eager', \"english!'\", 'sharply;', 'curiosity.', 'curled', 'uneasy:', '`shall', 'follow,', 'imagine', 'grinning', 'her;', \"dog's\", 'us!\"\\'', 'undoing', 'thing,', 'instead', '`--as', '`three', '`unimportant,', 'daughter', \"time?'\", \"`silence!'\", \"whiting,'\", 'distance', 'learning', 'creep', 'adventures--beginning', 'mine--a', \"`serpent!'\", \"true,'\", 'dear!', 'subjects', 'fancying', 'hers', '`can', 'manner', 'anything.', 'mouse--o', 'and,', 'prisoner', '`--i', 'person,', 'red-hot', 'on?', 'mark', 'though.', 'invitation', 'bowed,', \"`why?'\", 'things--everything', 'among', 'five.', 'me?', 'rustled', '`tut,', 'planning', 'chief', 'distance.', '`have', 'william', \"up.'\", 'last', 'replied,', \"first,'\", \"duchess,'\", 'difficult', 'foot!', \"advantage,'\", \"of?'\", 'returned', 'flying', 'beginning', 'own.', 'end', 'happen:', 'cakes', \"game.'\", 'yawning.', 'paw', 'antipathies,', 'pause.', \"not,'\", 'cheered,', 'running', 'diligently', 'usual', 'afore', 'grunted', \"can--'\", 'sister;', 'sobs.', 'ugh,', 'dormouse!', 'from', 'dressed,', \"shouldn't\", 'settle', 'croqueting', 'bag,', \"coward!'\", 'wearily.', \"pocket?'\", 'alone.', 'loose', 'prizes.', 'bat,', 'uncomfortable.', 'queer,', 'offended', 'miles', 'sharp', 'neat', 'jack-in-the-box,', '(not', \"suppose.'\", 'leaves', \"kind,'\", 'walk!\"', 'wings.', 'eye;', \"doing?'\", \"soup!'\", 'commotion', 'rome,', 'stopping', 'uncivil.', 'lessen', 'tried', 'story.', \"the--'\", 'hanging', \"cat's\", \"m--'\", 'livery,', 'come', 'golden', \"below!'\", 'persons', 'end,', 'nose,', 'fortunately', 'crying', '`chorus', 'salt', 'waistcoat-', 'aloud.', 'impossible', 'anywhere', 'if', 'scale!', 'rate!', 'do', 'frowning,', \"mind!'\", \"life.'\", 'placed', 'very', 'sleepy,', 'much.', 'passed;', \"right!'\", 'so.', 'field', 'king;', 'waistcoat-pocket,', 'stalk', '\"i\\'ll', '`nobody', 'executed,', '`wow!', 'crab,', \"too.'\", 'deal:', '`from', 'what?', 'strange,', \"order,'\", 'sea!\"', 'authority', \"wits!'\", 'goldfish', 'poor', \"minute!'\", 'children.', 'mouse,', 'magpie', 'guinea-pigs,', 'laughed', 'stick,', 'pieces.', 'rabbit,', \"`wouldn't\", \"sir--'\", 'uncommonly', 'bother', \"all,'\", 'dainties', \"cats.'\", 'use,', 'series', \"axis--'\", 'stay', 'beheaded,', \"executed.'\", 'puffed', \"fact.'\", \"bats?'\", 'treacle', 'thoughtfully', \"it.'\", \"that.'\", 'memorandum', \"else's\", 'ugly;', 'table:', 'dish?', 'forty-two.', 'mistake;', \"prison,'\", 'outside,', 'subject!', 'solemnly.', 'meat,', 'sighing', 'severely.', 'turned', \"to-day?'\", 'hare,', 'staring', \"dinner!'\", 'case', 'keeping', \"witness,'\", 'immense', \"talk!'\", \"yet,'\", 'clock', 'wait,', 'coming', 'forwards', 'losing', 'cried.', 'meaning', 'cake,', 'rule,', 'quick', 'roughly', 'humbly;', 'them--all', 'extremely', 'riddle', 'began:--', 'paper', 'trial:', 'executes', 'shaking', \"nonsense,'\", 'dive', 'opened', 'tea.', 'and--oh', 'leaves.', 'grass', 'name', \"me?'\", 'if--if', 'law,', 'use', 'eaten', 'offended.', 'yours', 'sharply', 'bore', \"cutting,'\", 'beautiful,', 'mary', 'happened.', 'standing', 'stretching', 'dormouse:', 'lacie,', 'wind,', 'somebody', 'sneeze', 'locked;', 'boxed', 'spades,', 'one', 'tarts?', \"meant,'\", 'door--i', \"star-fish,'\", 'are;', \"time,'\", 'present', 'watched', 'salmon,', \"nonsense.'\", 'what', \"here!'\", 'beating', 'subject', '`flamingoes', 'concluded', 'began:', 'whiting.', '`nothing', 'crowded', 'short', 'none', \"now,'\", 'uneasily', \"begin?'\", 'sign', 'thunderstorm.', 'wide', 'head--brandy', \"serpent!'\", 'draggled', 'then;', '`\"--found', '`just', '`fourteenth', \"it,'\", 'glaring', 'trampled', 'rate,', 'pattering', '`pepper,', 'side,', 'suppressed', 'meekly:', 'smile:', 'bathing', 'animals,', 'carefully,', '`anything', \"whatever?'\", \"housemaid,'\", 'suddenly,', 'far!\"', 'officers', \"they'll\", 'earnestly,', 'ii', 'wanted', 'queen.', 'together', 'toss', 'minding', 'one;', 'fanned', \"us,'\", \"`what's\", 'way.', 'wags', \"jaws!'\", 'see\"!\\'', \"one,'\", 'low', 'label', 'minute.', 'sky.', 'hurt', 'affair,', 'why.', 'another', 'signify:', 'venture', \"talk,'\", 'asleep,', 'bright', 'cautiously:', '(he', 'hit', \"answer?'\", 'thrown', 'seaography:', \"old,'\", 'myself,', '\"what', '`perhaps', \"so,'\", 'last:', 'telescope!', 'yet', '`speak', 'english', 'did', 'alice:', 'besides', 'us', \"confusing.'\", 'pardon,', 'sorrows,', 'upon', 'certain', 'fright', 'waited.', 'mad,', 'bottle,', 'timidly', \"caucus-race.'\", 'trickling', 'hated', 'saucer', 'claws', 'pretending', 'so--and', 'else.', 'accustomed', '`that', 'choke', \"coming!'\", 'dormouse;', 'pigs,', 'world', '`by-the-bye,', 'crawling', \"happens!'\", 'together,', 'girl', \"i'm\", 'justice', 'canterbury,', 'that:', 'over;', '(dinah', 'doze;', 'positively', 'quicker.', '`because', \"mystery,'\", 'bit.', '(`which', 'life.', 'silence', '`--but', 'footman.', \"partners--'\", 'fumbled', \"duchess's\", 'ought', 'two--\"', \"carrier,'\", \"fellow?'\", 'william,\"\\'', '\"there\\'s', \"were,'\", 'guard', 'speed', 'speaking,', 'comfits,', 'screaming', 'reply,', 'any.', 'sense,', 'baby;', 'england', \"crumbs.'\", 'box--', 'impatiently;', 'again!', 'head.', \"school,'\", 'accidentally', '`sit', 'nodded.', 'nor', 'in:', \"three.'\", \"pardon!'\", 'fellow?', 'him!', \"`you!'\", 'succeeded', \"right,'\", 'executions', 'hurry', 'loud.', 'rose-tree,', 'rats', '`my', 'alas!', 'away:', 'hastily;', '(or', \"`where's\", 'either', 'she', 'course', '`twenty-four', 'furious', 'immediate', 'proceed.', '`same', 'always', 'cheered.', 'dried', 'flat,', 'noise', 'gloves,', 'whatever', \"learn?'\", '`as', 'confusion', 'fly;', \"plan!'\", \"cats!'\", 'lullaby', \"said,'\", 'limbs', 'mouse:', \"is?'\", 'speaking', 'stays', \"time.'\", \"holiday?'\", 'sir,', 'chorus,', 'feel', \"`here!'\", '\"let', 'whom', 'gloves:', 'much', 'between', 'paris,', 'about.', 'someone', \"lessons!'\", 'begged', 'i', 'continued', 'instantly', 'anything', 'busily', 'you,', '`explain', 'then,', 'nothing;', '`she', \"more!'\", 'sending', 'duchess:', 'with,', 'tale,', \"needn't\", 'relieved', 'court;', 'knave.', 'avoid', 'snappishly.', 'welcome', 'were', '`explanations', 'mistake', 'over,', 'wandering', 'cat;', \"`creatures,'\", 'letter,', 'sob,', 'talk.', 'caught', 'tea,', 'finished,', 'ways', \"fourth.'\", 'began,', 'dispute', 'simply', 'dogs', 'edition', 'courage', 'dodged', '`--and', \"attending!'\", 'act', \"then.'\", 'variations.', \"weren't\", 'directed', 'chimney,', 'flurry', 'upset', 'take', \"grin,'\", 'explain', 'spoke;', 'friend.', 'verses', 'civil,', 'low-spirited.', 'startled', 'turtle', \"moment!'\", 'pigeon', 'indeed.', 'shoulders.', 'exact', 'royal', \"means.'\", \"names,'\", '`o', 'paws', \"with.'\", 'himself,', 'bones', 'rope--will', \"crumbs,'\", 'seen:', 'machines', 'appear,', 'plates', 'for,', \"moment's\", '`sh!', \"proceed,'\", 'fancy', 'queen', 'wept', '\"such', 'arithmetic--', \"better';\", 'disobey,', 'loveliest', 'slates.', 'powdered', 'felt', \"sea.'\", 'questions', \"say--that's\", 'heads.', \"mind.'\", 'rabbit:', 'difficulties,', 'dinner,', 'key,', 'quite', 'smaller,', 'opposite', '`--yes,', 'fond--of--of', 'though,', 'interrupted', 'easy', 'printed', 'solemnly,', 'sits', 'faces,', '`with', 'rapidly:', '`of', 'choking', 'tougher', 'jurors', '`--it', \"know--'\", '`mine', 'bring', 'unlocking', 'least--at', 'did,', 'meal,', 'to-day!', \"and-butter--'\", 'listen', 'treat.', 'timidly.', 'fell', 'size?', 'adventures,', 'footmen,', 'alice', 'ringlets', 'wood--(she', 'say,', 'down:', \"shan't\", 'wander', \"`i'm\", 'sternly.', 'deep,', 'shaped', 'pass', \"ask.'\", 'several', \"think!'\", 'summer', 'tea-time.', 'silence:', \"haven't\", \"plan.'\", 'suppressed.', 'turkey,', \"majesty!'\", 'angry,', 'resting', 'asked', 'game,', '(in', 'this,', \"impertinent,'\", 'circumstances.', '`important--unimportant--', \"lobsters!'\", 'well!', 'crawled', 'shall', 'faster?\"', 'follows', 'go?\"', 'stupid),', 'mineral,', \"tortoise--'\", 'provoking', \"mine.'\", 'chin.', '`sure', 'without--maybe', 'turning', 'order', \"there's\", \"majesty?'\", \"couldn't\", 'something;', 'finished', 'together:', 'crash)--`now,', 'straightening', 'here!', 'beasts', 'instance,', 'spectacles', 'form', 'nobody,', 'once', '(for,', 'shouted', 'state', \"different,'\", 'advice,', 'arrow.', 'anxious.)', \"afraid,'\", 'undertone', 'it', \"bit.'\", '`there', 'nasty,', \"matter,'\", 'look!', 'middle', '`this', 'bottle', 'sprawling', 'into', 'scaly', 'there', 'fairy-tales,', 'low,', 'blown', 'pause:', 'moment,', \"grin.'\", 'unhappy', 'means', \"again!'\", 'hot', \"clever?'\", 'other;', 'table.', 'breath,', \"dear?'\", 'pretty', 'second', 'curious', 'live', 'quiver', 'cheated', 'no!', 'footsteps', \"trial's\", 'spectacles.', 'never!', 'wasting', 'unusually', \"lessons,'\", 'edwin', 'singing', 'mark;', 'fall,', 'two:', \"him,'\", 'unjust', 'tears,', 'encouraging', 'in.', 'dishes.', 'spite', 'conclusion,', 'bats', 'editions', \"majesty,'\", \"railway,'\", 'music,', 'temper.', 'caterpillar,', '`nine', 'there,', 'alarm', 'our', 'kick', 'me,', 'nearer,', 'directly,', 'why,', 'repeating', 'had', 'box', 'death.\"\\'', 'yourself,', 'hatter', 'charges', 'wrong', 'talk:', 'rosetree;', 'vii', \"pardon,'\", \"yet?'\", 'march--just', 'chanced', 'eel', 'addressing', \"judge,'\", 'about;', 'right,', \"sobbing,'\", 'hatching', 'underneath', 'shelves', 'call', 'red', '`\"what', 'not.', 'tired', 'dinah', 'dishes', \"everything's\", 'go', 'pounds!', 'lizard', 'back', 'vi', 'once:', '`write', 'sound', 'you.', \"story.'\", 'words,', 'stuff', 'bear?--mind', 'shoulders', 'we', 'insult', 'angrily.', 'toes', \"me.'\", \"either!'\", 'ran', '`off', 'week:', 'fitted!', 'anxiously', 'louder', 'educations--in', \"now!'\", \"enough.'\", 'elbows', 'except', 'again;', 'slipped', 'year', \"mouse!'\", \"question?'\", 'wants', 'ringlets,', 'sang', 'slates,', 'dog', 'furiously,', 'morning?', \"in.'\", 'window,', \"heard!'\", 'larger,', 'dear', 'lark,', 'alas', '\"keep', \"child!'\", 'bent', 'plainly', 'gryphon;', 'rose-tree', 'queer', 'thump!', 'clubs;', \"before,'\", 'sister', 'around,', 'word)', 'whispered', 'person', 'dozing', 'taking', '`serpent,', 'hurry;', \"talking!'\", \"where.'\", 'bend', 'sneezing.', 'pat,', 'flower-beds', 'reduced', \"pun!'\", 'voice:', 'over)', 'eggs', 'northumbria,', 'grin,', 'steam-engine', 'stupid', 'stuff?', 'smile.', 'sea', '`each', 'ye;', 'ground--and', 'retire', 'frog-footman', 'balanced', \"alive!'\", 'relief.', 'am', 'bite.', '\"too', \"say?'\", 'silent.', 'treading', 'why', 'began.', \"couple?'\", 'chin:', 'rome--no,', 'overhead;', \"head!'\", 'end:', 'animal', 'show', 'followed', 'me!', 'you!', \"things!'\", 'puzzled.', 'bottle.', 'earth!', 'him,', 'shillings', 'liked', 'cross,', 'seaside', 'pleasure', 'anxious', 'anything,', 'pleasanter', 'chance', 'small.', 'miss', 'folded,', 'quadrille,', 'changed', 'pressed', '`all', 'hate--c', 'vague', 'whispers', 'left', 'patience', 'throne', 'quarrelled', \"don't!'\", 'garden,', 'merely', \"raw.'\", '`collar', 'yelp', 'kindly,', 'uncommon', 'remarked', 'one--but', 'shutting', 'fright.', '`we', 'cold', 'hedgehog.', 'balls', 'punished', \"`--where's\", \"`you'd\", 'engaged', 'gained', \"court!'\", \"day,'\", 'important', 'see,', '\"come', 'tone;', \"fashion.'\", 'shilling', '`ah!', 'various', 'earls', '`one', \"crazy!'\", 'is,', 'managed?', 'wore', \"`she's\", 'that.', 'bottom', 'trusts', 'vulgar', \"extras?'\", 'hardly', 'clean', 'dear:', 'eyes:', 'thousand', 'now.', 'shark,', \"ache!'\", 'fanning', \"extremely--'\", 'only', '`found', 'ever', 'and', 'eagerly:', 'wooden', 'bitter--and--and', 'appeared', 'baby', 'effect', '`once', 'mad.', 'saw', '`thank', 'seen--everything', 'watch', 'other:', 'fifth', 'mad--at', 'meet', 'white', \"day.'\", 'even', \"life!'\", \"twelfth?'\", 'pack', 'stoop?', 'appear', 'pence.', 'irritated', 'guinea-pig,', 'nothing:', 'but,', 'been', \"tale!'\", \"bill,'\", 'off).', '`did', 'rules', 'kitchen.', 'longitude', 'shining', \"croquet.'\", 'said:', 'twenty-four', 'reply.', 'twinkling', 'ran,', 'milk', 'conqueror,', \"course?'\", 'violently', \"sing?'\", 'place', 'quarrel', 'song,', 'already,', 'bread-and-butter,', 'journey,', 'arguments', 'flown', 'asking', 'direction,', 'tears', 'mouths--and', 'croquet-ground.', 'yet--and', 'jury-box,', '`his', 'well,', 'catching', \"happen,'\", 'ask!', 'inquired', 'gloves--that', 'things--i', 'write', '`talking', 'day.', 'taste', 'executioner:', \"`it'll\", 'elbow', 'toast,)', 'house', 'night!', \"'em\", 'age', '`digging', 'annoy,', 'seemed', 'crept', \"she,'\", 'for', 'turtle.', 'bread-and-butter.', \"first.'\", '`soles', 'said,', 'life', 'scolded', 'day!', \"`very,'\", 'rate', 'fish)--and', 'could,', 'how', 'hall', '\"it\"', 'silence.', \"pig!'\", \"alone!'\", 'lips.', 'small', 'was', 'english);', \"much!'\", 'deeply,', '`the', 'them,', 'hare', 'line', 'sulky,', 'precious', 'cheeks,', \"`no,'\", 'night?', \"they're\", 'beautify', 'upsetting', 'cat.', 'puppy;', 'nearer', \"butter,'\", '\"much', \"man.'\", 'hid', 'does,', 'teaching', 'then--i', \"mine,'\", 'again--\"before', 'through', \"sisters,'\", 'patted', 'desperate', \"late!'\", 'voice,', 'beast,', 'with;', 'certainly:', 'by', 'a', \"chose,'\", \"caucus-race?'\", 'doubled-up', 'head!', 'rabbits.', 'altogether,', 'quadrille', 'neighbouring', 'none,', 'luckily', \"here,'\", 'their', \"cat,'\", 'drawling,', 'fact.', 'fits,', 'ought!', 'party.', 'found', 'emphasis,', \"`hadn't\", 'lobster', 'occasional', 'terror.', \"tea--'\", 'sharks', 'tails', 'before.', 'beat', 'enough;', \"hatter's\", 'cart-horse,', 'atom', \"him.'\", 'sorrow,', \"yet!'\", 'march', 'recovered', 'school', 'burst', \"from,'\", \"yet--it's\", 'hope', \"like.'\", 'explanation.', 'enough--i', 'disgust,', \"it!'\", 'cup', 'passing', \"that's\", 'difficulty', \"puss,'\", \"opinion,'\", 'stand', \"i'll\", 'passage', 'faster,', \"`well!'\", 'pray', 'earth.', 'longer', 'pepper-box', \"business,'\", \"know,'\", \"lesson-books!'\", \"william,'\", 'till', \"writing-desk?'\", 'invented', 'cause,', 'fellows', 'tipped', 'clapping', 'sit', 'patiently', 'on.', \"thimble';\", 'man,', \"this?'\", 'learnt', 'severely', 'settled', 'asleep.', 'drop', 'raving', 'pulling', 'cat', \"conversation?'\", 'may', 'pinched', 'her', 'answer', 'did.', 'above', 'neighbour', 'tulip-roots', 'of', 'tone', \"i--'\", 'feelings.', 'drinking.', 'tortoise,', 'hurry,', \"different!'\", \"`treacle,'\", 'gay', 'reminding', 'livery', 'day,', 'angry', 'baby,', 'said,)', 'am,', 'produced', 'french', 'garden.', 'become', \"curious.'\", 'fast', 'game', 'true):', 'change:', \"all.'\", 'processions;', 'down.', 'curiosity,', 'distant', 'remaining', 'sounded', \"won't!'\", 'muscular', '`oh!', \"dancing.'\", 'shyly,', 'scroll,', 'laughed,', 'know.', \"see!'\", 'now?', 'height.', 'beating.', \"`yes,'\", 'reeds--the', 'him;', \"australia?'\", 'capital', '`--that', 'beak--', 'game.', 'fly', 'spectacles,', 'carry', \"adventures.'\", 'tail.', 'ear', 'swim.', \"done,'\", \"morning,'\", 'today.', 'snorting', 'bend,', 'country', 'time).', 'head!\"\\'', \"so.'\", '`suppose', 'returning,', \"haven't,'\", \"you,'\", \"idea,'\", \"concert!'\", 'feet!', 'five', 'tea-tray', \"i've\", 'exclaimed', 'else\"--but,', 'ear.', 'time', 'beds', 'grass,', 'high:', 'towards', 'say', '(`i', 'race', 'pink', 'cheshire', 'name,', 'sand', 'sobbing', '(sounds', 'sigh,', 'floor:', 'jaw,', 'hung', 'owl', 'rearing', 'head:', 'is--\"the', \"story!'\", 'please!', \"day--'\", 'knowledge,', 'calmly,', 'more;', '`hush!', 'leaving', 'share', 'whereupon', 'wonder', 'lessons,', 'tremble.', 'anger,', 'appealed', \"man,'\", \"jury-box,'\", 'rule:', 'i?', 'with.', '\"william', 'dipped', 'swimming', 'offend', \"window.'\", 'everybody', \"see.'\", 'eaglet.', '\"turtle', 'earth', 'content', 'far', 'spoke,', 'managed', 'cautiously', '(the', 'contempt.', \"mad?'\", 'appeared,', '`--for', 'things', \"`it's\", 'growled', 'all:', 'wink', 'moved.', 'arch', 'brave', 'fluttered', 'generally,', 'search', 'stupidest', 'pronounced', 'writing-desks,', \"warning,'\", 'crown', \"pardoned.'\", \"is.'\", 'choked', 'lose', 'butter,', 'scream,', 'fury,', 'gryphon.', 'ferrets!', 'rattle', 'evidently', 'adjourn,', 'herself;', 'punching', 'jar', \"`you've\", \"honour!'\", 'on', 'past', 'red.', \"dreadful,'\", 'curly', 'arches.', 'wow!', 'two,', 'morcar,', 'rabbit;', 'hundred', 'remarking,', 'patiently.', 'vanishing', 'in', 'moral,', 'waving', 'one,', 'size', 'sends', 'livery:', 'manners', 'english,', 'cards:', 'air,', 'sigh.', '\"i', '(before', 'mabel', 'crab', 'tail,', 'coaxing', \"house!'\", 'roof.', 'happen,', 'paper.', '`seals,', 'accident', 'company', 'dreamy', 'curious,', 'far,', 'angrily:', 'picture.)', 'happens;', 'is', '(when', '`why,', 'but', 'dropped,', 'shriek,', \"doesn't\", 'soothing', 'falling', 'pity!\"?\\'', \"dogs?'\", 'rippling', 'repeated,', '`pray', \"usual,'\", 'go.', \"done.'\", 'tone.', 'understood', 'night-air', 'heap', \"sir,'\", 'puzzling', 'door--', \"be.'\", \"them,'\", 'answer,', 'exclaimed,', \"now--don't\", 'delay', 'knelt', 'good-bye,', 'interest', 'triumphantly.', 'slate-pencil,', 'dry', 'pity.', 'be', 'rabbit-hole', 'keep,', 'poker', 'fountains,', 'checked', 'quickly', 'lory,', 'own', 'swallowing', 'kings', 'ask:', 'remarks,', \"coils.'\", 'really', 'theirs,', 'missed', 'king,', 'writhing,', 'myself', 'rather', 'while,', 'age,', 'tells', 'possibly', 'saves', 'xii', \"to?'\", 'shiver.', 'peeping', 'want', 'invent', 'indeed:--', 'tut,', 'purring,', 'open,', 'lizard,', 'peering', 'been,', 'strings:', 'yards', '`soo--oop', 'yours:', 'tarts', 'sky!', \"m?'\", 'land', '`after', \"removed!'\", 'fan!', 'large', 'oblong', \"queen!'\", 'subject.', 'passion,', 'tears!', 'banquet--]', 'strength,', \"never')\", 'rustling', '`it', 'expecting', \"quadrille?'\", \"tomorrow--'\", 'nine', 'little', 'downward!', 'wrapping', 'directly.', 'size;', \"here?'\", 'thought),', 'fat;', '[later', 'sister,', 'him:', 'minutes.', 'other', 'at!\"', \"`nothing,'\", 'shade:', 'mischief,', 'bright-eyed', 'then--always', 'listened,', 'hold', 'lasted', 'flew', 'cardboard.)', \"music.'\", \"too,'\", \"it's\", 'loudly.', 'trims', 'gryphon:', \"seems,'\", 'was,', 'uncomfortable,', \"case,'\", 'foot,', 'giving', 'two', \"garden!'\", '`besides,', 'hearth', 'worse.', 'hot,', 'understand', 'then?', 'flavour', 'faintly', 'rich', 'alone', \"somewhere.'\", \"shan't!\", \"weeks!'\", \"ordered';\", 'across', 'wandered', 'doorway;', 'house,', 'cat.)', 'shoulders,', 'open', 'muchness\"--did', 'eggs,', \"once.'\", 'knowledge', 'clamour', 'deeply', 'playing', '`come', \"do.'\", 'paws.', 'dance?\"\\'', 'watching', 'pour', 'voice.', 'duchess,', \"thing,'\", '`well!', 'mabel,', 'sense', 'tight', 'knowing', \"chatte?'\", 'pie', 'told', 'soup?', 'mouse', 'folding', \"creatures,'\", 'treated', 'itself,)', 'needs', '`either', 'ordering', 'flamingo:', 'violence', \"it--'\", 'spoke.', 'currants.', \"a--i'm\", \"verse,'\", 'month,', 'energetic', 'earnestly.', '(if', \"through,'\", \"that'll\", \"ears--'\", 'fair', 'centre', 'deal', 'speak', 'good-naturedly', 'head,', 'skirt,', \"hatter.'\", 'mouse?', 'failure.', 'received', \"head's\", 'life,', '`a', \"`idiot!'\", 'white;', 'floor,', \"idiotic!'\", \"up!'\", 'breathe\"!\\'', 'worm.', 'crumbs', 'courage,', 'ten', 'lobsters,', \"nonsense!'\", '`and', 'went,', 'darkness', 'knowledge.', '`but', 'prove', 'minutes', 'kills', 'happy', 'position', 'this', 'conversations', 'softly', 'father,', 'witness.', 'long,', 'first--they', 'knocking,', 'trouble,', 'yet,', 'mentioned', 'edgar', 'thoughtfully:', \"be,'\", 'hedgehog', \"`unimportant.'\", 'bowed', 'sure,', 'grazed', 'violently,', 'tastes!', 'kitchen', 'washing--extra.\"\\'', 'tears.', '(a', 'slate', '\"he\\'s', 'daisy-chain', 'scratching', 'carrying', 'hour', \"sorrow?'\", 'neatly', 'encouraged', 'itself', 'manage', 'hearing.', \"find?'\", 'perhaps', 'notice', 'sensation', 'honour,', 'piteous', \"pie--'\", \"`hjckrrh!'\", \"hush!'\", 'curving', 'accounts', 'feathers,', 'back,', \"present!'\", '`two', \"on.'\", \"won't'\", 'soup,', 'wig,', \"water-well,'\", \"`don't\", 'deep', 'cherry-tart,', 'dreamed', 'everything', 'draw,', \"whiting!'\", 'thought,', 'only,', 'three-legged', 'day;', 'angry.', 'sight:', 'almost', 'grief,', 'tried.', 'afford', \"escape!'\", \"trying--'\", \"ann!'\", \"together.'\", 'tittered', 'nose.', 'oneself', 'twelve?', 'decided', 'pale,', '`now', 'took', 'furrow', \"explained,'\", \"be?'\", 'mind,', 'under', \"suppose?'\", 'tops', 'undo', 'cushion,', 'long', 'broke', 'cunning', 'engraved', 'argued', 'mercia', 'encourage', 'silence,', 'violent', '\"you', 'absence,', 'ran.', \"mushroom,'\", 'away,', 'feebly', \"end,'\", 'serpents!', \"slates'll\", 'tea--not', 'dodo,', 'toffee,', 'room.', 'you--all', 'officer', '`oh,', 'done.', 'long;', 'brass', \"with,'\", 'dunce?', \"all!'\", 'looked', \"them!'\", 'creatures', 'however,', 'first,', 'bone', 'fishes', 'delightful', 'tidy', 'sort.', 'hand.', '`--or', '`cheshire', \"where--'\", 'breath.\"', 'marched', \"things?'\", 'natural', 'knows', 'takes', 'high.', 'simple', 'seeing', 'fire-irons', \"indeed,'\", 'ridge', 'leaves:', 'once,', 'kneel', 'door', 'clock.', 'honest', 'flinging', 'jogged', '`up,', 'good,', \"curiouser!'\", 'child,', 'cat,', 'fight', 'her.', 'noticed,', 'was!', 'dear,', 'bats,', 'saucepans,', 'something,', \"see,'\", \"off.'\", 'trials,', 'knew)', 'itself.', 'sneezes:', 'snail', 'sun,', 'mournful', 'win,', 'frog;', 'nowhere', '\"how', 'lifted', 'oh!', 'schoolroom,', 'know--no', \"`ahem!'\", 'tie', 'seated', 'hoped)', 'kill', \"turtle's\", 'somersault', 'drive', '`chop', 'pinch', 'sweet-tempered.', 'read', 'joined', 'frowning', \"`i've\", 'see--how', 'noises,', 'faces', '`living', 'hurry:', 'prize', 'soo--oop!', 'court,\"', 'fellow!', 'child:', 'sometimes', 'nurse!', \"does.'\", 'less', 'wherever', 'you--are', \"offended!'\", 'evening,', 'bark', 'screamed', '`mary', 'yer', 'happened,', 'thistle,', 'roared', 'sight,', 'hands,', 'here,', 'next!', 'ignorant', 'goes', 'grew', 'these', '`until', 'remark', 'asked,', 'going,', 'rest,', 'natural);', 'hair!', 'thatched', 'jurymen.', \"sea--'\", 'best,', \"`poison,'\", 'anger', 'farmer,', 'fulcrum', 'broken', 'waiting', 'muchness--', \"prisoner's\", 'terrier,', 'lie', \"manage?'\", 'cupboards', 'draw', 'conger-eel,', 'curtain', \"unimportant--important--'\", 'guess', 'outside.', 'shut', 'dripping', 'over', \"sh!'\", 'woman--', 'conclusion', 'free', 'suet;', 'some', 'absurd', 'tumbling', 'us.', 'pity', \"away,'\", 'thanked', \"things--'\", 'half', 'lewis', 'yours.\"\\'', 'nibbled', 'spoon', 'magic', \"her,'\", 'cook,', 'begin,', \"onions.'\", \"outside,'\", \"twinkle--'\", 'tied', 'won,', \"feet!'\", 'entangled', \"waiting!'\", \"stupid?'\", \"shall!'\", 'you', 'again.)', '`an', 'barley-sugar', 'grant', 'exclamation', \"end.'\", 'leap', 'child-life,', 'appeared;', 'attempt', 'mabel!', 'dry,', 'immediately', 'ventured', 'murdering', 'suppose', 'farther', 'licking', \"`everything's\", \"like,'\", \"thing!'\", 'crashed', \"think.'\", 'before,', 'child', 'both', 'yesterday,', 'confused', 'older', 'arrived,', 'birds,)', 'civil', 'finish,', 'lastly,', 'knave', 'away.', 'sea.', \"well--'\", 'whisper.)', 'english.', 'pack,', 'father', 'buttered', 'pool--she', 'turns', 'doors', 'round!\"\\'', 'must,', 'zealand', 'real', '`leave', 'respectable', 'think', 'wood,', '`does', 'stopped', 'thoughts', \"afterwards.'\", \"again,'\", 'sure!', 'simply--\"never', 'book-shelves;', \"whiskers!'\", 'likely', \"egg!'\", 'usual.', 'flock', 'lonely', \"washing?'\", \"figure,'\", \"spot.'\", 'mouth;', \"well,'\", 'daisies,', \"`arrum.')\", 'enormous', 'deserved', \"mean,'\", 'nicely', 'have', 'shriek', 'time.)', 'pretend', 'ask', 'evidence', 'pressing', 'apples,', 'hands;', 'knew,', 'rising', 'home', '`sentence', 'being', 'wildly', 'secret,', \"alice's\", 'boy,', 'leaders,', 'cats:', 'eye,', 'lamps', 'arranged;', 'mouths;', 'comfortable,', 'anxiously.', 'butter', 'once;', 'forepaws', 'classics', 'thought', 'grave', 'clear', \"did!'\", 'sea,', 'interrupted,', 'voice;', 'pie-crust,', 'something', 'cleared', 'lovely', 'knee', \"perhaps?'\", 'move', '`nearly', 'finger;', \"tasted--'\", \"`you'll\", 'doing', 'paris', \"whiles.'\", 'face.', 'deeply.', 'feeble,', 'blasts', '`drink', 'clinging', 'started', 'voices--`hold', \"are!'\", \"then!'\", 'attempted', 'attends', 'melancholy', 'break.', 'wood', 'tale', \"song?'\", 'chose', 'laid', 'bear:', 'old,', '`come,', 'never-ending', \"cats?'\", 'plate', 'bats?', \"bit!'\", \"it?'\", 'anything;', \"figures!'\", \"away!'\", 'caused', \"court.'\", '`oh', \"asleep,'\", 'inches', 'largest', 'dancing', 'given', 'stretching,', 'cat!', 'this.', 'cost', 'canary', 'gloves.', 'changed,', \"turtle.'\", 'cook', 'nose', 'courage.', 'ix', 'exclaimed.', 'panting,', 'x', 'drew', 'talk', 'wet', 'known', 'accounting', 'speak--and', 'off', \"course,'\", 'spread', 'do.\"', 'splendidly', 'cares', \"do?'\", 'protection.', '`ah,', 'ago:', 'dormouse,', 'dinah!', 'each', \"business!'\", 'catch', 'questions,', 'row', 'zigzag,', 'table,', 'sleepy;', 'pigs', \"you.'\", 'sentence', \"wow!'\", 'to', 'triumphantly,', 'rapped', '(and,', \"day!'\", 'safe', \"they'd\", 'queens,', 'advisable--\"\\'', 'poured', 'thought;', 'opened,', 'feelings', 'raised', \"grunt,'\", 'panted', 'green,', 'my', 'neck,', 'week', 'bad', 'blame', '`change', '`hand', 'gone.', 'rattling', 'cackled', 'cries', '`seven', '`hold', 'shouting', 'well.', 'met', \"accusation!'\", 'excellent', 'possible', 'creatures.', 'queer-', 'looking', 'cauldron', 'argument', 'like,', \"watch,'\", 'course,', 'sneezed', 'hearts,', 'way?', 'days.', 'court!', 'here', 'skurried', 'soldier', \"giddy.'\", 'lost,', 'mice--oh,', \"didn't,'\", 'round', \"what's\", 'times', 'mouths.', '(for', 'couples:', 'already', \"prizes!'\", 'silent', 'useful,', \"i'd\", 'capering', 'trying', 'presented', 'indignant', 'pine-apple,', \"were',\", 'flame', 'cur,', 'nice,', \"down!'\", 'attended', 'flowers', 'appeared.', \"o'clock\", 'kind', 'them:', 'spell', 'with', 'dropping', \"dormouse's\", \"`why,'\", 'splash!', 'replied;', \"`important,'\", \"clearly,'\", '(`the', 'are,', 'proved', 'live.', 'try', 'singers', 'crossed', 'pictures', 'over.', 'custody', 'comes,', 'jury', 'fury:', 'mouth', 'splashed', 'ones', 'daresay', 'says', 'follows:--', 'up,', 'suit', 'respect.', 'next', 'end!', 'laugh;', \"ever,'\", 'sound.]', \"think--'\", 'visit', '(it', 'nevertheless', 'ferrets', 'flapper', 'lying', 'pool', 'tell', \"which?'\", \"muchness?'\", 'seriously,', 'loving', 'master', 'mile', \"sea-shore--'\", 'ointment--one', \"you'll\", 'has', '\"there', 'he', 'off;', 'next,', '`which', 'parts', 'before', \"breathe.'\", 'dismay,', 'blades', 'goose!', \"beginning,'\", 'sad', 'asking,', 'hungry', 'lobster;', \"elbow.'\", 'viii', 'sleep', 'jury.', 'easily', 'pleaded', 'politely,', '`w.', 'worry', 'nile', 'more', \"be!'\", '`why', 'nose--', 'verse', 'alice.', 'history,', 'repeat', 'hare:', 'nurse--and', 'execute', 'acceptance', 'memory,', 'proud', '`are', 'tone:', 'ridiculous', 'mock', 'passage,', 'notion', 'creature', 'mad', 'as', 'taller', 'disappointment', 'was:', 'key', '`repeat,', 'saw.', 'many', 'slate.', 'snail.', 'seven', 'producing', 'understand.', 'conquest.', '`than', 'children', 'interesting,', 'execution.', 'unpleasant', 'dropped', 'nibbling', 'feather', 'near', 'affectionately', 'grinned;', \"he'd\", 'minutes,', '`yes,', 'clasped', 'made', \"again?'\", '\"who', 'rumbling', 'occasionally;', 'mouse--a', \"one.'\", 'sadly.', 'said.', 'jumped;', \"animal's\", 'side', 'prosecute', 'good-', 'any', 'knot,', 'appearance', 'highest', 'within--a', \"porpoise.'\", 'somehow', 'until', 'gravely.', \"to,'\", \"then,'\", 'gather', \"`yes!'\", 'smiling', 'sell', 'hollow', 'singers.', 'seems', 'able!', \"speak?'\", '`without', 'further.', 'injure', '`beautiful', 'answer.', 'thoroughly', 'ah,', 'queen!', 'hunting', 'close', 'its', 'know', \"remedies--'\", 'nearly', 'brown,', 'iv', 'hair', '`what!', 'course;', 'nose;', \"think,'\", \"little,'\", \"sister's\", 'uncomfortable', 'croquet-ground', 'moment', 'buttercup', 'here;', 'day-school,', 'corner', \"yet.'\", 'happens', 'delighted', 'taught', 'enough,', 'broken.', 'telling', 'queen,', 'label,', 'like\"!\\'', 'children,', 'right-hand', \"dinah'll\", 'cushion;', 'awfully', \"throat,'\", \"executioner's\", 'middle,', 'gave', 'ordered.', 'sleepy', \"are,'\", 'multiplication', 'duchess.', 'sobbed', 'pat!', 'all,', 'shake', 'voices', 'alice!', 'doth', 'names', 'whether', '`i--i', 'angrily', 'noticing', 'adventures', 'roast', 'effect:', 'fish,', \"toes?'\", \"can,'\", 'chimney', \"what?'\", 'child;', 'sorts', 'askance--', '`back', 'sentenced', \"lady,'\", \"go,'\", 'hatter,', 'judge,', 'sighing.', '`now,', 'slightest', 'way,', \"brother's\", 'eaglet', 'sharing', 'worse', 'suddenly', 'impatient', '`unless', 'six', 'moment:', \"size,'\", 'backs', 'ledge', 'wider.', 'latitude', 'sorry', '`ten', 'upset,', 'ma', 'turtles,', 'larger', 'small,', 'time.', 'water', 'those', 'whistling.', 'month', 'serpents', 'down', 'fountains.', 'on,', \"them--'\", 'handed', '`give', \"stay!'\", 'uglification,', 'pointing', 'too:', 'pencils', 'turtle--we', 'surprise', 'court', 'moral', 'afraid', \"fancy--who's\", \"hat,'\", 'bursting', 'words:--', 'ashamed', \"pleases!'\", 'squeezed', 'stool', 'particular', \"is,'\", 'mind', '`i', 'fifteen', 'reason', 'pennyworth', \"no!'\", 'closely', 'bat!', \"bird,'\", 'grow', 'cried', 'inkstand', 'graceful', 'other--bill!', 'by--the', 'bird', \"let's\", 'persisted.', 'getting', 'glad', \"puppy's\", 'garden:', 'his', 'meanwhile', 'houses,', 'gone', 'resource,', 'that', 'pleased.', 'you?', 'wife;', \"person!'\", 'sharply,', 'snail,', 'size:', 'remarked,', 'right', 'family', 'out,', 'refused', '`right,', 'improve', 'shrill,', 'temper', \"hadn't\", 'usurpation', 'turtle,', 'howling', 'timidly,', 'sides', \"youth,'\", 'bough', 'tones', 'suppress', 'barking', 'distraction,', 'pet:', 'changing', 'air', '`only,', 'hurt,', 'rabbit', 'promised', '`--likely', 'burning', 'pocket', 'peeped', 'learned', 'twice', 'soft', 'washing', 'attempts', 'indeed,', 'within', \"ill.'\", 'frontispiece', '`certainly', 'riper', 'interrupted.', 'finishing', 'duchess', 'hand,', \"late.'\", 'learn!', 'least', 'tasted', 'again:--', 'finished.', 'locks,', \"march.'\", \"to--'\", 'same', 'again', 'mouths', 'prevent', 'guinea-pig', 'chains,', 'camomile', 'handsome', \"maybe,'\", '`\"will', 'vote', 'moving', 'things,', 'remembered', \"wig.'\", 'blow', 'lives.', 'custard,', \"witness.'\", 'paw,', '`go', \"knocking,'\", 'came', 'it;', 'plates,', 'courtiers;', 'be,', 'conversation', 'regular', 'soup,\"', 'gravely,', 'face,', 'promising,', 'readily:', 'see:', '`in', 'way!', 'joined):--', 'branch', 'purple.', \"yourself,'\", 'below', 'surprise.', 'time,', 'think:', 'large,', 'mouse.', 'generally', 'impatiently,', 'slowly,', 'cucumber-frames', 'coast', 'fish-footman', 'never', 'dormouse.', 'snatch', 'seen,', 'hours,', \"was!'\", 'often', \"nose';\", 'crown.', 'laughing', \"lines!'\", \"to-day.'\", 'witness', 'twelve', 'taller,', 'kitchen,', 'lit', 'swallowed', 'sky', 'water.', 'meant', 'different', 'flamingo', 'hastily', 'doubt:', 'involved', 'little!', \"`jury-men'\", 'trembled', 'wandering,', \"stop.'\", 'mouse--to', 'happen', 'eats', 'writing', 'believed', 'heavy', 'that--only', 'confusing', 'fixed', \"shoes!'\", 'glanced', 'killing', 'birthday', 'straight', 'guessed', 'heart', 'nest.', 'wonderland,', 'remained', 'ladder?--why,', \"rude.'\", 'curtseying', '(with', \"figure!'\", 'sulky', \"ada,'\", 'passionate', 'sluggard,\"\\'', 'twinkling!', 'shape', \"he'll\", 'stairs.', 'hare.', 'growing,', 'helpless', 'turtles', \"stuff,'\", 'world!', '`wake', 'struck', 'body', 'along', \"all?'\", 'morals', 'tarts,', 'himself', 'knife,', 'rubbed', 'ears', '`\"we', 'tea', 'hoarse,', 'boon,', 'it),', 'finish', \"one's\", 'dish', 'keep', 'bill!', 'replied', 'linked', 'eye', \"not?'\", \"back!'\", 'went.', 'yelled', 'together.', 'pencil', \"myself.'\", 'perfectly', 'again:', 'nonsense.', 'trumpet', \"shorter.'\", 'nurse', 'blacking,', 'all!', '`here!', 'beautiful', \"finished,'\", \"better.'\", 'duchess!', 'arches', 'close,', \"had!'\", 'paint', '*', 'can', '`twinkle,', \"behind?'\", '`prizes!', 'dates', 'first.', 'rightly', 'home!', \"dogs.'\", 'ate', 'furrows;', 'chorus', 'it.', '`silence', 'fine', 'mustard', 'do:--', 'finds', 'tea-things', 'other.', 'while', 'twenty', 'pieces', 'majesty', \"won?'\", 'love).', 'brought', 'uncomfortably', 'best.', \"instead!'\", 'curls', 'howled', 'croquet', 'archbishop', 'eleventh', 'hippopotamus,', 'they', \"well?'\", 'fire,', 'sugar', 'whisper', \"invited,'\", 'duck:', \"`it's--it's\", 'marked,', 'know--and', 'present--', 'bawled', 'it!', 'fond', 'that?--it', 'crimson', 'directions,', \"fun!'\", 'certain!', 'neither', 'tea;', \"beheaded!'\", \"them.'\", 'personal', 'hint;', 'key;', 'door:', 'maps', 'hatter.', 'gloomily:', \"waist,'\", 'laughing:', 'elegant', 'got', 'paws!', 'vanished.', \"story,'\", 'last,', \"watch!'\", 'a-piece', 'letters.', \"`fifteenth,'\", '(pointing', 'trees,', 'politely:', 'lesson-book.', 'empty:', \"getting!'\", 'unwillingly', 'out', 'despair', 'meekly', 'knew', 'had,', 'same,', 'mouse--of', 'way:--', 'chapter', \"prizes.'\", 'burn', 'rude,', 'send', \"oyster!'\", \"won't\", 'faces.', 'seven.', \"not';\", 'happened.)', 'judging', 'effect,', 'roof', 'stretched', 'delight', 'dodo.', '`turn', 'pocket)', 'mournfully.', \"sort,'\", 'first', \"rabbit's\", 'concert', 'is--\"birds', 'would', 'shock', 'boots', '`behead', 'proves', 'hall.', \"game,'\", 'cannot', 'care', 'note-book,', 'indignantly.', 'barrowful', 'hungry,', 'weak', 'slipped,', 'party', 'lesson', \"`ugh!'\", \"trying.'\", 'aloud,', 'twice,', 'muddle', 'consented', 'sort', 'alarm.', 'book', 'father;', \"say!'\", \"pig,'\", 'particular;', '`how', 'legs', \"others!'\", 'then', \"beginning!'\", 'passed', 'declare', 'beauti--ful', '`some', 'different.', 'ann!', \"sing,'\", \"she'd\", \"over!'\", 'condemn', 'listening,', 'all.', 'righthand', 'frog', 'themselves.\"\\'', 'gently', 'baby:', 'below,', 'stairs!', '`please', \"history,'\", \"draw?'\", 'millennium', 'minute,', 'spoon:', 'reasons.', 'now,', 'on!\"', \"high,'\", '`may', 'cook.', 'woman;', 'riddles', 'living', 'hatter:', 'whisper,', 'dead', '`swim', 'it,)', \"again.'\", 'hoarsely', 'often,', \"whiting?'\", '`on', 'down--here,', '_i_', 'him.', 'solemn', 'lost:', 'flat', 'too', 'said;', 'else', 'ann,', '`however,', 'sharply.', \"he's\", '`stuff', 'exactly', 'lap', 'plenty', 'sing', 'against', \"`i'll\", 'guess,', '`drive', 'escape;', 'people', 'did:', 'fit--\"', 'kick,', 'please', 'corners:', 'stupidly', 'least,', '`consider,', 'conversation.', 'confusion,', 'leading', \"he?'\", 'used', 'answered', 'frying-pan', 'teacups', 'france--', 'bound', 'offended,', 'chorus.', '`begin', 'pebbles', 'shore,', 'otherwise,', 'stigand,', 'bells,', 'alice,', \"conqueror.'\", \"removed,'\", 'goose,', \"twice--'\", \"can't\", 'because', 'assembled', 'drawing', 'nonsense', \"`there's\", 'puzzled', \"`let's\", 'heads', 'drawling-master', '`they', 'glass', 'fender,', '`bring', 'guinea-pigs', 'truth:', 'more--as', 'splashing', 'change', \"before.'\", 'dormouse', 'morning,', 'once.', 'hedgehogs;', 'opportunity', 'dream.', 'skimming', 'chuckled.', \"not.'\", 'die.', 'think,', \"one?'\", 'twinkle,', 'slates;', 'hedge.', \"wasn't\", 'dark', 'picked', 'that!', 'promise.', \"roses?'\", 'hearts', 'growl,', 'back.', 'an', 'young', 'twinkle--\"\\'', 'shook', 'telescopes:', 'pigeon;', \"`they'd\", 'air.', 'supple', \"mind,'\", 'crocodile', 'grand,', 'that;', 'right;', 'dream,', 'honour:', 'waited', 'humbly:', 'wet,', 'should', 'doubtfully,', 'deepest', 'feared', 'me', 'best', 'moved', \"`stupid,'\", 'sun.', 'now--but', 'jury,', 'boldly:', 'name:', 'again,', 'where', '`do', 'top', 'number', 'too,', 'proposal.', '`for', 'again.', 'voice:--', 'roses.', 'vanished', 'like', 'him),', 'cheerfully', 'hers--she', 'difficulty,', 'after', 'disappeared;', \"must,'\", 'fun', 'head--', 'footman', 'plan,', 'velvet', '`stand', 'escape', '(as', 'narrow', 'terribly', 'flower-pot', 'played', \"chimney!'\", 'spreading', 'out-of-the-way', \"words.'\", 'actually', 'recognised', 'looking-', 'serpent;', 'procession', '`sure,', 'hoping', 'hurried', 'chrysalis--you', 'eyelids,', 'good', 'unfolded', 'better', 'cartwheels,', 'song', \"really?'\", 'distance--but', 'odd', 'gravy,', 'whistle', '`no', 'wondered', \"we're\", 'do,', '`their', \"days.'\", 'hoarse', 'beg', '(alice', 'sleep,', 'first;', 'wonderful', 'bleeds;', 'read:--', 'kettle', 'forehead', 'murder', 'contemptuous', 'rush', 'mice', 'poky', 'hookah,', 'high', \"derision.'\", 'moment.', \"guilt,'\", 'fan', \"king's\", 'angrily,', 'hatters', \"`sixteenth,'\", 'squeeze', 'believe', 'shakespeare,', \"believe.'\", '`read', '(we', '--come,', 'pigeon.', 'history.', 'eels,', 'do.', 'grin', 'glass.)', 'begin', 'brushing', 'could', 'cake.', 'quietly,', '`advance', 'fur', 'hair.\"', 'experiment', 'roots', 'she,', 'collected', 'knocked.', 'ring,', 'hall:', 'fit)', 'him--it', 'follow', 'ask.', 'quarrelling', 'not,', \"for.'\", '`look', 'rapidly;', 'hand', 'unhappy.', 'wash', 'gryphon', 'seen', \"outside.'\", 'ugly', 'parchment', \"curious!'\", \"i!'\", 'touch', '`please,', 'wag', 'means,', 'doubling', 'officers:', 'denies', \"say,'\", 'rabbit-hole--and', 'presently', 'favoured', 'shut.', 'disappeared.', 'race-course,', 'closed', 'like:', 'manner,', 'it.)', 'shower', '`or', 'buttons,', \"table,'\", 'sobs,', 'begins', 'do:', 'is--oh', \"longer!'\", \"english,'\", \"dormouse!'\", 'hint', 'eat\"', 'besides,', 'closer', 'miserable', \"words,'\", 'them--`i', 'pairs', \"sky-rocket!'\", 'larger:', '`curiouser', 'hear', 'hide', 'forgotten', \"on!'\", 'fancy,', 'question.', 'sands', 'repeated', 'remarkable', \"throat!'\", \"rabbit'\", 'wild', 'confused,', 'suddenly:', 'est', \"`dinah's\", 'downwards,', '`then,', 'garden.\"\\'', 'holding', 'drowned', \"girl,'\", 'flashed', 'continued,', 'making', 'trial,', 'unless', 'pictured', 'fancied', 'enjoy', \"then?'\", 'bowing', 'face--and', 'opening', 'tea-time,', 'gloves', 'trial', 'sudden', 'air!', 'out.', '`if', \"treacle-well.'\", 'pretexts', \"temper,'\", 'done', 'solid', '`herald,', 'rabbit!', '`shy,', 'harm', 'upright', 'saucepan', \"annoyed,'\", 'toys', 'talking.', 'oh,', 'say.)', 'steady', \"bit,'\", \"won't,\", 'know,', 'play', 'another!', 'dodo', \"`she'd\", 'words', 'argue.', 'mean,', 'tillie;', 'setting', \"little!'\", \"then!--bill's\", 'indeed', 'thing', 'duck.', 'please,', 'offer', 'nothing', 'tree.', 'm,', 'whiskers,', 'to?', 'dreaming', 'turtle;', 'agony', '`nor', 'breeze', '`what', 'gardeners,', 'now', 'humble', 'off.', 'happens.', '(luckily', 'completely.', 'uneasily,', \"guinea-pigs!'\", 'upstairs,', \"now?'\", 'latin', 'clearer', '`first', 'invited', 'queerest', 'this:--', 'expressing', 'whose', 'finding', \"begun.'\", 'is!', 'kid', 'grand', 'unable', 'fainting', 'shorter,', '`till', \"perhaps,'\", \"partner!'\", '`orange', 'on:', 'lowing', 'folded', \"important,'\", 'run', \"dormouse,'\", 'fly,', \"handwriting?'\", 'is--\"be', 'submitted', \"teases.'\", 'mine,', 'dance.', 'uglify', 'him--how', 'pulled', 'such', '3.0', 'creature,', 'full', 'made.', 'well', 'audibly.', \"me,'\", 'counting', 'book,', 'sulkily', 'change,', 'mouse-traps,', 'slippery;', \"hedges,'\", 'fact', 'denied,', \"marmalade',\", \"refreshments!'\", 'must', 'oh', 'fix', 'most', 'her:', \"works!'\", 'question,', 'about', 'dull', \"say.'\", '`whoever', 'knee,', 'elsie,', 'coming.', 'rise', 'squeaked.', 'feeble', \"bed!'\", 'sensation,', 'length', '`one,', 'speak,', 'story', 'bad,', 'slate--oh,', \"`'tis\", 'forgetting', 'showing', 'languid,', 'people.', 'scrambling', 'stingy', 'silent,', 'new', 'find', 'drawling--the', 'forgot', 'moon,', 'leave', 'eyes,', \"`once,'\", 'dance', 'imitated', \"eggs,'\", 'tricks', 'note-book', 'particular.', 'signifies', 'direction', 'figure', 'also,', '`boots', \"`alice!'\", 'high).', 'garden', 'girls', 'flustered', \"dear,'\", 'themselves', '`let', \"answers.'\", \"places!'\", 'unfortunate', 'overcome', 'than', 'yourself', '`really', 'sent', 'is--\"oh,', 'fan,', 'voice', 'haste,', 'foot.', 'trying,', 'shrink', 'brush,', 'gazing', 'ground,', 'does', \"do!'\", 'white,', '`was,', '`somebody', 'tortoise', 'breathe', 'ancient', '\"uglification,\"\\'', \"`who's\", 'waste', '`tell', 'rate:', '`thinking', 'turn', 'list,', 'few', 'indeed:', 'join', 'them', 'hopeful', '`get', 'ran;', 'thistle', 'esq.', \"'tis\", '\"--said', \"yourself!'\", \"more.'\", 'cucumber-frame,', 'contemptuously.', 'added,', 'snout', 'soldiers', 'dig', 'shoulder,', 'pig,', 'introduced', 'becoming.', 'cattle', 'at', 'set', \"baby?'\", 'free,', 'surprise,', 'thing.', 'edge', 'grammar,', \"dear!'\", 'pleasing', 'puppy', 'footman,', \"sort!'\", 'wide,', 'answered,', 'glass;', 'chin', 'youth,', \"sea,'\", 'undertone,', '`to', \"in?'\", '`lives', 'hurry.', 'timidly;', 'soo--oop', 'fit', 'cause', 'lazily', 'shingle--will', 'hearthrug,', 'bread-', \"mouse's\", 'arm,', \"you've\", 'jurymen', '`only', 'ordered', 'man', 'hearts.', 'master,', 'hall,', 'slates', 'high,', 'fashion,', 'look-out', 'listen,', 'water,', 'serpent,', \"we've\", 'voice--the', 'more.', 'milk-jug', 'no,', '`who', 'said', 'out.\"', 'entrance', 'remarked.', 'plate.', \"telescope.'\", 'doubtfully:', 'blew', \"`they're\", 'dears?', 'finger', 'mallets', 'words:', 'raven', 'eagerly.', 'door,', 'round,', 'soon.', 'jelly-fish', 'caucus-race', \"better,'\", 'escape,', \"saying.'\", 'whiting', 'otherwise.\"\\'', 'sadly:--', 'talking:', 'lost', 'life;', \"direction,'\", \"sea!'\", 'eyes.', 'without', 'alive', 'ambition,', 'also', \"know.'\", 'crash', 'rabbit.', 'loud', 'vegetable.', 'grumbled:', 'fidgeted.', \"king,'\", 'up', \"don't\", 'dinah,', \"christmas.'\", 'kept', 'normans--\"', 'jury-box', 'remember', 'get', 'dream', 'winter', 'double', 'rubbing', '`really,', 'you:', 'indignantly,', \"witness!'\", \"lizard's\", 'walk', 'thick', \"uglifying!'\", \"`dinah'll\", 'eyes;', 'will', 'learn', 'bringing', 'there.', 'lived', \"off--'\", 'smoking', 'treacle-well--eh,', 'song.', 'saying', 'next.', \"you'd\", \"dinn--'\", 'yawned', 'begun', 'line:', '\"up', \"likes.'\", 'trot', \"cards!'\", \"was.'\", 'familiarly', 'locks', 'riddles.--i', 'airs!', '`any', 'you,\"\\'', 'quiet', \"(`that's\", 'presents', 'smallest', 'frighten', 'true--\"', 'growls', 'nobody', 'things!', \"ground.'\", 'question', 'roses', 'tinkling', 'one!', 'instantly,', '`then', 'word', 'died', 'tide', 'hurrying', 'be\"--or', 'cat:', 'face', 'went', 'sorrowful', 'advantage', 'twinkled', 'interrupting', 'friend', 'life!', 'mustard-mine', '`but,', '`everybody', 'knuckles.', 'lay', \"know!'\", 'near.', 'dare', 'no', 'teeth,', 'son,', 'tail', \"room!'\", 'think;', 'fur.', 'to--to', \"together!'\", 'expected:', 'farm-yard--while', 'suppose,', 'hurriedly', 'came,', 'turns,', 'ravens', 'puzzled.)', '`mouse', 'pale', \"fig?'\", 'pepper', 'unrolled', 'ridges', 'hands', 'birds!', \"william's\", 'filled', 'crossly:', 'bank,', 'just', 'lessons', '(which', 'ready', 'fireplace', '`reeling', 'queer-looking', 'does.', 'turn;', 'place,', 'directions', 'teacup', \"verses.'\", 'knave,', 'globe', \"way--'\", 'old', 'sooner', 'stamping', 'xi', 'crowd', 'called', 'shrieked', \"`he's\", 'late', 'eaglet,', 'mushroom,', \"cup,'\", \"much,'\", 'dear!\"', 'all', 'fact,', 'others', 'tree', 'for?\"\\'', 'kissed', 'alice,)', 'patriotic', 'soup.', 'scroll', 'comfortably', \"feeling!'\", 'speech', 'four', 'porpoise,', 'candle.', 'delight,', 'behind', 'alice;', 'word,', 'certainly', 'players,', 'shoulder', 'comes', 'been.', 'beheading', \"`moral,'\", 'belong', 'courtiers,', '`--so', \"toes.'\", 'little,', 'eagerly,', 'thought:', \"`they--you've\", 'us,', 'get\"', \"from?'\", 'feeling', \"`that's\", 'picking', 'dinah:', 'stiff.', 'sight.', 'existence;', 'doubt,', \"wood,'\", \"window!'\", 'were.', 'comfits:', 'threw', 'round.', 'garden--how', \"less,'\", 'players', 'way', 'inclined', 'questions.--how', 'dreadful', 'sobs', 'days', 'passage:', 'sisters--they', 'worth', 'pitied', 'branches', 'eagerly', 'inquisitively,', \"begin.'\", \"that!'\", 'birds', '--the', \"wine,'\", 'managing', \"fairly,'\", 'sight;', \"knot!'\", \"`can't\", 'sticks', 'liked,', 'bread-and-butter', 'sadly', 'arm-in-arm', 'railway', '`call', 'practice', 'narrow,', 'meaning.', 'more:', 'soon', 'herself', 'other,', 'ground', 'doubtful', 'help', \"heads!'\", 'trembling', 'knife', 'untwist', 'deny', 'as,', 'hastily.', 'grown', 'natured,', 'laughter.', 'brightened', 'hedgehog,', 'tumbled', \"croquet?'\", 'height', 'shared', 'arm', 'beautifully', 'adoption', 'consultation', 'soup', 'nursing', '`would', \"means--to--make--anything--prettier.'\", 'remarked;', 'lock,', \"that,'\", 'is--\"take', 'trotting', 'work', 'chimneys', 'scream', 'lazy', 'lad!--here,', 'favourite', '(though', 'are', 'lodging', 'back-somersault', 'inwards,', 'coaxing.', 'digging', 'pair', 'from:', 'night', \"a--'\", \"right?'\", 'cry', 'swam', 'tiptoe,', '\"french,', \"tea,'\", 'ready?', 'advice', \"dream!'\", 'expression', 'idea', \"last!'\", 'extraordinary', 'ceiling,', '--but', '`--change', 'love,', '`so', 'replied.', 'sneeze,', 'atheling', 'foolish', 'changes', 'eyes', '`poor', 'throwing', \"way?',\", 'comfort,', \"stairs!'\", 'remembering', 'procession,', 'trees', 'true.)', \"was,'\", 'beau--ootiful', 'tea-party', \"lobster--'\", 'beasts,', \"here.'\", 'curtsey', 'thirteen,', 'yesterday', 'mixed', 'twentieth', 'can;', 'vinegar', 'spoken', 'attending', 'five!', \"bill's\", 'feet', \"d,'\", \"other.'\", 'noticed', 'messages', 'yet--oh!', 'so,', 'persisted', 'rest', 'distance,', \"duchess?'\", 'telescope', 'move.', 'respectful', \"lessons?'\", \"window?'\", 'interrupt', 'panther', 'matters', 'eyes--and', '`keep', 'fallen', 'go,', 'throw', 'brain;', 'stand,', 'tiny', 'dance?', \"shoes.'\", 'reaching', 'along--`catch', 'usually', \"somebody.'\", 'became', 'arm-chair', 'this;', 'history', 'asking!', 'thin--and', 'examining', 'histories', 'green', \"for?'\", 'cats', \"not!'\", 'circle,', 'tongue,', \"simpleton.'\", 'on;', \"like?'\", 'bank--the', 'impossible.', '`take', 'complaining', 'busy', 'corner,', 'mouth,', \"you!'\", 'meeting', 'somewhere', 'leant', '`no,', \"`we're\", 'stood', 'books,', '`stupid', 'about,', 'table', 'break', 'solemnly', 'altogether;', 'air:', 'flung', 'half-past', \"hasn't\", 'mean', 'declared', 'belt', \"did,'\", 'belongs', 'faster', 'come,', 'secondly,', 'it?)', 'sure;', 'thank', 'door;', 'shore.', '\"they', 'sat', 'could.', 'left,', 'whole', \"`nonsense!'\", \"serpent?'\", 'guests,', '`not', \"now.'\", \"puzzle!'\", \"to.'\", 'king', 'hate', 'added', 'declare,', 'go!', 'chimney?--nay,', 'dears', \"queen,'\", 'lobsters', \"any,'\", \"first!'\", 'arms,', '(look', \"`i'd\", 'serpent.', 'applause,', 'every', 'here.', 'happened', \"part.'\", 'make', \"ma'am,\", 'lately,', 'little--\"\\'', 'pig', 'alive;', 'replied:', 'whispered,', 'shoes', 'shrill', 'walked', 'clever', 'abide', 'crouched', 'surprised', 'reply', \"procession,'\", '`at', \"game's\", 'subdued', \"bat?'\", 'might,', 'result', '`crumbs', 'all;', 'glass.', 'sigh:', 'cross-examine', 'late,', 'plan', 'more,', 'advance', 'pleased,', \"this!'\", '\"with', 'together.\"\\'', 'two.', 'saying,', 'footsteps,', 'jury,\"', 'duck', \"temper!'\", 'butterfly,', 'push', 'entirely', \"isn't\", 'usual,', 'reach', 'speech,', 'lest', 'it,', 'nervous,', 'nothing,', 'it--once', 'altogether.', \"speaker,'\", 'drunk', 'animals', 'longed', \"alice's,\", 'children;', 'queen:', 'part', 'introduce', 'leaning', \"prizes?'\", \"growing.'\", 'reading', 'room,', 'pleasant', 'fork', 'pigeon,', 'painting', \"doing!'\", 'lady', 'settling', 'geography.', '`consider', \"hot-tempered,'\", 'lory', 'used--and', \"t!'\", 'pig-baby', 'was)', '\"edwin', 'give', 'first--verdict', 'walrus', \"wrong!'\", 'v', 'bee,\"', 'crash,', 'raising', \"pace,'\", 'stirring', 'spoke--fancy', \"question,'\", 'surprised,', \"subject,'\", 'talking', 'began', 'signed', 'alarmed', 'ornamented', 'considered', \"there,'\", \"trial.'\", 'claws,', 'politely;', 'are!', 'asleep', 'absurd,', 'whiskers!', 'sight', \"axes,'\", \"is--'\", 'wise', 'listening:', 'considering', \"like!'\", 'three,', 'five,', 'though),', 'foot', 'candle', \"shiny?'\", \"verdict,'\", \"fun?'\", 'having', '`--you', 'passion.', 'fighting', 'i,', 'shepherd', 'herself,', 'measure', 'temper,', 'tone,', 'it:', \"next!'\", 'allow', \"child,'\", 'strange', 'choosing', 'soup!', 'look', \"bill!'\", 'glass,', 'this:', 'to-night,', 'advance!', \"yourself.'\", 'low.', 'thoughtfully.', 'incessantly', \"tongue!'\", 'flappers,', 'years,', 'common', 'hours', '`fetch', 'complained', 'reason,', 'hedgehogs', 'fall', \"home,'\", 'reasonable', 'sink', \"dull!'\", 'flamingo.', 'not', '`rule', 'time!', 'uncorked', '\"\\'tis', 'constant', 'denied', 'denying', \"think?'\", 'leaves,', 'permitted', 'cool', 'croqueted', \"about!'\", 'shedding', 'tossing', 'list', 'guests', 'hiss', 'slowly', 'makes', 'explanation;', 'rushed', 'taken', 'pool,', 'who', \"indeed!'\", 'listen.', \"remember,'\", 'neck', 'speech.', 'nice', 'please:', 'king.', 'quietly', 'wrote', 'three', 'held', \"sad?'\", 'putting', 'hall;', 'friends', 'sometimes,', \"mad.'\"}\n",
            "Average sentence length: 7.4\n",
            "Vocabulary diversity: 0.1870\n"
          ]
        }
      ],
      "source": [
        "def assess_data_quality(texts):\n",
        "    \"\"\"Analyze text data quality for Word2Vec training\"\"\"\n",
        "\n",
        "    stats = {\n",
        "        'total_documents': len(texts),\n",
        "        'total_words': 0,\n",
        "        'unique_words': set(),\n",
        "        'sentence_lengths': [],\n",
        "        'word_frequencies': {}\n",
        "    }\n",
        "\n",
        "    for text in texts:\n",
        "        words = text.lower().split()\n",
        "        stats['total_words'] += len(words)\n",
        "        stats['sentence_lengths'].append(len(words))\n",
        "        stats['unique_words'].update(words)\n",
        "\n",
        "        for word in words:\n",
        "            stats['word_frequencies'][word] = stats['word_frequencies'].get(word, 0) + 1\n",
        "\n",
        "    stats['vocabulary_size'] = len(stats['unique_words'])\n",
        "    stats['avg_sentence_length'] = sum(stats['sentence_lengths']) / len(stats['sentence_lengths'])\n",
        "\n",
        "    # Find most common words\n",
        "    sorted_words = sorted(stats['word_frequencies'].items(), key=lambda x: x[1], reverse=True)\n",
        "    stats['top_words'] = sorted_words[:20]\n",
        "\n",
        "    # Quality indicators\n",
        "    stats['quality_score'] = {\n",
        "        'vocabulary_diversity': stats['vocabulary_size'] / stats['total_words'],\n",
        "        'avg_word_frequency': stats['total_words'] / stats['vocabulary_size'],\n",
        "        'rare_words_ratio': sum(1 for count in stats['word_frequencies'].values() if count == 1) / stats['vocabulary_size']\n",
        "    }\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Example usage\n",
        "quality_report = assess_data_quality(texts)\n",
        "print(f\"Total documents: {quality_report['total_documents']:,}\")\n",
        "print(f\"Vocabulary size: {quality_report['vocabulary_size']:,}\")\n",
        "print(f\"Unique Words: {quality_report['unique_words']}\")\n",
        "print(f\"Average sentence length: {quality_report['avg_sentence_length']:.1f}\")\n",
        "print(f\"Vocabulary diversity: {quality_report['quality_score']['vocabulary_diversity']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaq-kMXMD5Uw"
      },
      "source": [
        "### **1.3 Text Processing Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "dCZ4Ivp1D4ky"
      },
      "outputs": [],
      "source": [
        "#Import Packages\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tag import pos_tag\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6au3u0aDDzl4",
        "outputId": "3e02c42a-8cce-4143-b305-35cabb570c4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "587Ebyk7EEUR"
      },
      "outputs": [],
      "source": [
        "class AdvancedTextPreprocessor:\n",
        "    \"\"\"Comprehensive text preprocessing for Word2Vec training\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 lowercase=True,\n",
        "                 remove_punctuation=True,\n",
        "                 remove_numbers=False,\n",
        "                 remove_stopwords=False,\n",
        "                 min_word_length=2,\n",
        "                 max_word_length=50,\n",
        "                 lemmatize=False,\n",
        "                 remove_urls=True,\n",
        "                 remove_emails=True,\n",
        "                 keep_sentences=True):\n",
        "\n",
        "        self.lowercase = lowercase\n",
        "        self.remove_punctuation = remove_punctuation\n",
        "        self.remove_numbers = remove_numbers\n",
        "        self.remove_stopwords = remove_stopwords\n",
        "        self.min_word_length = min_word_length\n",
        "        self.max_word_length = max_word_length\n",
        "        self.lemmatize = lemmatize\n",
        "        self.remove_urls = remove_urls\n",
        "        self.remove_emails = remove_emails\n",
        "        self.keep_sentences = keep_sentences\n",
        "\n",
        "        if remove_stopwords:\n",
        "            self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        if lemmatize:\n",
        "            self.lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Clean individual text string\"\"\"\n",
        "\n",
        "        # Remove URLs\n",
        "        if self.remove_urls:\n",
        "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "        # Remove email addresses\n",
        "        if self.remove_emails:\n",
        "            text = re.sub(r'\\S+@\\S+', '', text)\n",
        "\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        #Combined\n",
        "         #(r'https?://\\S+|www\\.\\S+|<.*?>|\\S+@\\S+\\.\\S+|@\\w+|#\\w+|[^A-Za-z0-9\\s])\n",
        "\n",
        "        return text\n",
        "\n",
        "    def tokenize_text(self, text):\n",
        "        \"\"\"Tokenize text into sentences or words\"\"\"\n",
        "\n",
        "        if self.keep_sentences:\n",
        "            # Tokenize into sentences first\n",
        "            sentences = sent_tokenize(text)\n",
        "            processed_sentences = []\n",
        "\n",
        "            for sentence in sentences:\n",
        "                words = self.process_sentence(sentence)\n",
        "                if len(words) >= 3:  # Keep sentences with at least 3 words\n",
        "                    processed_sentences.append(words)\n",
        "\n",
        "            return processed_sentences\n",
        "        else:\n",
        "            # Return single list of words\n",
        "            return self.process_sentence(text)\n",
        "\n",
        "    def process_sentence(self, sentence):\n",
        "        \"\"\"Process individual sentence\"\"\"\n",
        "\n",
        "        # Lowercase\n",
        "        if self.lowercase:\n",
        "            sentence = sentence.lower()\n",
        "\n",
        "        # Tokenize into words\n",
        "        words = word_tokenize(sentence)\n",
        "\n",
        "        processed_words = []\n",
        "        for word in words:\n",
        "\n",
        "            # Remove punctuation\n",
        "            if self.remove_punctuation:\n",
        "                word = word.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "            # Skip if empty after punctuation removal\n",
        "            if not word:\n",
        "                continue\n",
        "\n",
        "            # Remove numbers\n",
        "            if self.remove_numbers and word.isdigit():\n",
        "                continue\n",
        "\n",
        "            # Check word length\n",
        "            if len(word) < self.min_word_length or len(word) > self.max_word_length:\n",
        "                continue\n",
        "\n",
        "            # Remove stopwords\n",
        "            if self.remove_stopwords and word in self.stop_words:\n",
        "                continue\n",
        "\n",
        "            # Lemmatize\n",
        "            if self.lemmatize:\n",
        "                word = self.lemmatizer.lemmatize(word)\n",
        "\n",
        "            processed_words.append(word)\n",
        "\n",
        "        return processed_words\n",
        "\n",
        "    def preprocess_corpus(self, texts):\n",
        "        \"\"\"Preprocess entire corpus\"\"\"\n",
        "\n",
        "        all_sentences = []\n",
        "\n",
        "        for text in texts:\n",
        "            if not isinstance(text, str):\n",
        "                continue\n",
        "\n",
        "            # Clean text\n",
        "            cleaned_text = self.clean_text(text)\n",
        "\n",
        "            # Tokenize and process\n",
        "            processed = self.tokenize_text(cleaned_text)\n",
        "\n",
        "            if self.keep_sentences:\n",
        "                all_sentences.extend(processed)\n",
        "            else:\n",
        "                all_sentences.append(processed)\n",
        "\n",
        "        return all_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj00KAt8EGf6",
        "outputId": "7d7b81bf-5b75-4eb1-c9e9-7e625895b980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 2941 sentences\n",
            "Sample sentence: ['alice', 'adventures', 'in', 'wonderland']\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "preprocessor = AdvancedTextPreprocessor(\n",
        "    lowercase=True,\n",
        "    remove_punctuation = True,\n",
        "    remove_numbers=True,\n",
        "    remove_stopwords=False,  # Keep stopwords for Word2Vec\n",
        "    lemmatize=False,  # Usually not needed for Word2Vec\n",
        "    keep_sentences=True\n",
        ")\n",
        "\n",
        "# Processing corpus\n",
        "processed_sentences = preprocessor.preprocess_corpus(texts)\n",
        "print(f\"Processed {len(processed_sentences)} sentences\")\n",
        "print(f\"Sample sentence: {processed_sentences[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4IL4GasEITB",
        "outputId": "88513770-37c2-4345-e3cf-890e9f97360b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['alice', 'adventures', 'in', 'wonderland'],\n",
              " ['the', 'millennium', 'fulcrum', 'edition'],\n",
              " ['down', 'the', 'rabbithole']]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_sentences[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIMschYGEKtW"
      },
      "source": [
        "### **1.4 Training Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "GEXyyhf0EYZm"
      },
      "outputs": [],
      "source": [
        "def recommend_parameters(corpus_size, vocab_size, domain_type, computing_resources):\n",
        "    \"\"\"\n",
        "    Recommend Word2Vec parameters based on corpus characteristics\n",
        "\n",
        "    Args:\n",
        "        corpus_size: Number of sentences/documents\n",
        "        vocab_size: Unique words in vocabulary\n",
        "        domain_type: 'general', 'technical', 'social_media', 'academic'\n",
        "        computing_resources: 'limited', 'moderate', 'high'\n",
        "    \"\"\"\n",
        "\n",
        "    recommendations = {}\n",
        "\n",
        "    # Vector size based on corpus and vocab size\n",
        "    if corpus_size < 10000:\n",
        "        recommendations['vector_size'] = 50\n",
        "    elif corpus_size < 100000:\n",
        "        recommendations['vector_size'] = 100\n",
        "    elif corpus_size < 1000000:\n",
        "        recommendations['vector_size'] = 200\n",
        "    else:\n",
        "        recommendations['vector_size'] = 300\n",
        "\n",
        "    # Window size based on domain\n",
        "    domain_windows = {\n",
        "        'general': 5,\n",
        "        'technical': 3,  # More syntactic focus\n",
        "        'social_media': 4,\n",
        "        'academic': 6    # More semantic focus\n",
        "    }\n",
        "    recommendations['window'] = domain_windows.get(domain_type, 5)\n",
        "\n",
        "    # Min count based on corpus size\n",
        "    if corpus_size < 10000:\n",
        "        recommendations['min_count'] = 1\n",
        "    elif corpus_size < 100000:\n",
        "        recommendations['min_count'] = 2\n",
        "    elif corpus_size < 1000000:\n",
        "        recommendations['min_count'] = 5\n",
        "    else:\n",
        "        recommendations['min_count'] = 10\n",
        "\n",
        "    # Algorithm selection\n",
        "    if domain_type in ['technical', 'academic']:\n",
        "        recommendations['sg'] = 1  # Skip-gram for rare technical terms\n",
        "    else:\n",
        "        recommendations['sg'] = 0  # CBOW for general text\n",
        "\n",
        "    # Epochs based on corpus size and resources\n",
        "    if computing_resources == 'limited':\n",
        "        recommendations['epochs'] = 5\n",
        "    elif corpus_size < 100000:\n",
        "        recommendations['epochs'] = 15\n",
        "    else:\n",
        "        recommendations['epochs'] = 10\n",
        "\n",
        "    # Hierarchical softmax vs negative sampling\n",
        "    if vocab_size > 100000:\n",
        "        recommendations['hs'] = 1\n",
        "        recommendations['negative'] = 0\n",
        "    else:\n",
        "        recommendations['hs'] = 0\n",
        "        recommendations['negative'] = 10\n",
        "\n",
        "    return recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7d3-yTLEbFV"
      },
      "source": [
        "### **1.5 Step-by-Step Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSd9285uEip9",
        "outputId": "90c3431a-5ee5-43eb-997c-2650e1ea1be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Du3mF83WElMp"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "import time\n",
        "import multiprocessing\n",
        "\n",
        "class EpochLogger(CallbackAny2Vec):\n",
        "    \"\"\"Callback to log information about training progress\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_begin(self, model):\n",
        "        print(f\"Epoch #{self.epoch} start\")\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        elapsed = time.time() - self.start_time\n",
        "        print(f\"Epoch #{self.epoch} end - Time elapsed: {elapsed:.2f}s\")\n",
        "        self.epoch += 1\n",
        "\n",
        "def train_word2vec_model(sentences, save_path=None, **params):\n",
        "    \"\"\"\n",
        "    Train Word2Vec model with given parameters\n",
        "\n",
        "    Args:\n",
        "        sentences: List of tokenized sentences\n",
        "        save_path: Path to save the model\n",
        "        **params: Word2Vec parameters\n",
        "    \"\"\"\n",
        "\n",
        "    # Set default parameters\n",
        "    default_params = {\n",
        "        'vector_size': 100,\n",
        "        'window': 5,\n",
        "        'min_count': 5,\n",
        "        'workers': multiprocessing.cpu_count() - 1,\n",
        "        'sg': 0,  # CBOW\n",
        "        'epochs': 10,\n",
        "        'alpha': 0.025,\n",
        "        'min_alpha': 0.0001,\n",
        "        'hs': 0,\n",
        "        'negative': 10\n",
        "    }\n",
        "\n",
        "    # Update with provided parameters\n",
        "    default_params.update(params)\n",
        "\n",
        "    print(\"Training Word2Vec model with parameters:\")\n",
        "    for key, value in default_params.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    # Add callback for progress monitoring\n",
        "    epoch_logger = EpochLogger()\n",
        "\n",
        "    # Train the model\n",
        "    print(f\"\\nTraining on {len(sentences)} sentences...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    model = Word2Vec(\n",
        "        sentences=sentences,\n",
        "        callbacks=[epoch_logger],\n",
        "        **default_params\n",
        "    )\n",
        "\n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
        "    print(f\"Vocabulary size: {len(model.wv)} words\")\n",
        "\n",
        "    # Save model if path provided\n",
        "    if save_path:\n",
        "        model.save(save_path)\n",
        "        print(f\"Model saved to {save_path}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuNFve87EnWC",
        "outputId": "e63f747a-741a-4a9d-82bf-caec4ec89661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Word2Vec model with parameters:\n",
            "  vector_size: 50\n",
            "  window: 5\n",
            "  min_count: 1\n",
            "  workers: 1\n",
            "  sg: 0\n",
            "  epochs: 15\n",
            "  alpha: 0.025\n",
            "  min_alpha: 0.0001\n",
            "  hs: 0\n",
            "  negative: 10\n",
            "  compute_loss: True\n",
            "\n",
            "Training on 2941 sentences...\n",
            "Epoch #0 start\n",
            "Epoch #0 end - Time elapsed: 0.43s\n",
            "Epoch #1 start\n",
            "Epoch #1 end - Time elapsed: 0.55s\n",
            "Epoch #2 start\n",
            "Epoch #2 end - Time elapsed: 0.69s\n",
            "Epoch #3 start\n",
            "Epoch #3 end - Time elapsed: 0.83s\n",
            "Epoch #4 start\n",
            "Epoch #4 end - Time elapsed: 0.99s\n",
            "Epoch #5 start\n",
            "Epoch #5 end - Time elapsed: 1.14s\n",
            "Epoch #6 start\n",
            "Epoch #6 end - Time elapsed: 1.26s\n",
            "Epoch #7 start\n",
            "Epoch #7 end - Time elapsed: 1.37s\n",
            "Epoch #8 start\n",
            "Epoch #8 end - Time elapsed: 1.47s\n",
            "Epoch #9 start\n",
            "Epoch #9 end - Time elapsed: 1.57s\n",
            "Epoch #10 start\n",
            "Epoch #10 end - Time elapsed: 1.72s\n",
            "Epoch #11 start\n",
            "Epoch #11 end - Time elapsed: 1.94s\n",
            "Epoch #12 start\n",
            "Epoch #12 end - Time elapsed: 2.13s\n",
            "Epoch #13 start\n",
            "Epoch #13 end - Time elapsed: 2.30s\n",
            "Epoch #14 start\n",
            "Epoch #14 end - Time elapsed: 2.40s\n",
            "\n",
            "Training completed in 2.40 seconds\n",
            "Vocabulary size: 2519 words\n",
            "Model saved to word2vec_model.model\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "model = train_word2vec_model(\n",
        "    sentences=processed_sentences,\n",
        "    save_path='word2vec_model.model',\n",
        "    vector_size=50,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    epochs=15,\n",
        "    compute_loss = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za30iGqqEokl",
        "outputId": "c9f51c39-bd5a-413a-c410-dc9d9c0bc881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 2519\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(model.wv.index_to_key)\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajOAvhrtEpp9",
        "outputId": "c369f2c3-f98f-4a0c-a4ce-06ce52fa3299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Words in Vocabulary: ['the', 'and', 'to', 'it', 'she', 'of', 'said', 'you', 'in', 'was']\n"
          ]
        }
      ],
      "source": [
        "all_words = model.wv.index_to_key\n",
        "print(\"All Words in Vocabulary:\", all_words[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byvEbeWEEr8G"
      },
      "source": [
        "### **1.6 Model Evaluation and Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "N44rjB_CEy9D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class Word2VecEvaluator:\n",
        "    \"\"\"Comprehensive evaluation suite for Word2Vec models\"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.wv = model.wv\n",
        "\n",
        "    def evaluate_word_similarity(self, word_pairs_with_scores):\n",
        "        \"\"\"\n",
        "        Evaluate model on word similarity datasets\n",
        "\n",
        "        Args:\n",
        "            word_pairs_with_scores: List of tuples (word1, word2, human_score)\n",
        "\n",
        "        Returns:\n",
        "            Spearman correlation with human judgments\n",
        "        \"\"\"\n",
        "\n",
        "        model_similarities = []\n",
        "        human_similarities = []\n",
        "\n",
        "        for word1, word2, human_score in word_pairs_with_scores:\n",
        "            try:\n",
        "                model_sim = self.wv.similarity(word1, word2)\n",
        "                model_similarities.append(model_sim)\n",
        "                human_similarities.append(human_score)\n",
        "            except KeyError:\n",
        "                # Skip if words not in vocabulary\n",
        "                continue\n",
        "\n",
        "        if len(model_similarities) < 10:\n",
        "            print(\"Warning: Too few valid word pairs for reliable evaluation\")\n",
        "            return None\n",
        "\n",
        "        correlation, p_value = spearmanr(human_similarities, model_similarities)\n",
        "\n",
        "        print(f\"Word Similarity Evaluation:\")\n",
        "        print(f\"Valid pairs: {len(model_similarities)}\")\n",
        "        print(f\"Spearman correlation: {correlation:.4f}\")\n",
        "        print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "        return correlation\n",
        "\n",
        "    def evaluate_analogies(self, analogy_dataset):\n",
        "        \"\"\"\n",
        "        Evaluate model on word analogy tasks\n",
        "\n",
        "        Args:\n",
        "            analogy_dataset: List of tuples (word_a, word_b, word_c, word_d)\n",
        "                           representing \"word_a is to word_b as word_c is to word_d\"\n",
        "\n",
        "        Returns:\n",
        "            Accuracy on analogy task\n",
        "        \"\"\"\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        #('king', 'queen', 'man', 'woman'),\n",
        "        for word_a, word_b, word_c, expected_d in analogy_dataset:\n",
        "            try:\n",
        "                # Predict word_d\n",
        "                result = self.wv.most_similar(\n",
        "                    positive=[word_a, word_b],\n",
        "                    negative=[word_c],\n",
        "                    topn=1\n",
        "                )\n",
        "\n",
        "                predicted_d = result\n",
        "\n",
        "                if predicted_d[0][0].lower() == expected_d.lower():\n",
        "                    correct += 1\n",
        "\n",
        "                total += 1\n",
        "\n",
        "            except (KeyError, IndexError):\n",
        "                # Skip if words not in vocabulary\n",
        "                continue\n",
        "\n",
        "        if total == 0:\n",
        "            print(\"Warning: No valid analogies found\")\n",
        "            return 0\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "        print(f\"Analogy Evaluation:\")\n",
        "        print(f\"Valid analogies: {total}\")\n",
        "        print(f\"Correct predictions: {correct}\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    def evaluate_odd_one_out(self, word_groups):\n",
        "        \"\"\"\n",
        "        Evaluate model's ability to identify odd words in groups\n",
        "\n",
        "        Args:\n",
        "            word_groups: List of lists, each containing words where one doesn't belong\n",
        "\n",
        "        Returns:\n",
        "            Accuracy on odd-one-out task\n",
        "        \"\"\"\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for group in word_groups:\n",
        "            if len(group) < 3:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Find the word that doesn't match others\n",
        "                odd_word = self.wv.doesnt_match(group)\n",
        "\n",
        "                # This is tricky - we need ground truth to evaluate properly\n",
        "                # For now, just check if the model can identify AN odd word\n",
        "                correct += 1  # Placeholder - you'd need labeled data\n",
        "                total += 1\n",
        "\n",
        "            except KeyError:\n",
        "                continue\n",
        "\n",
        "        if total == 0:\n",
        "            return 0\n",
        "\n",
        "        accuracy = correct / total\n",
        "\n",
        "        print(f\"Odd-One-Out Evaluation:\")\n",
        "        print(f\"  Valid groups: {total}\")\n",
        "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    def analyze_vocabulary_coverage(self, test_texts):\n",
        "        \"\"\"\n",
        "        Analyze how well model vocabulary covers test texts\n",
        "\n",
        "        Args:\n",
        "            test_texts: List of text strings\n",
        "\n",
        "        Returns:\n",
        "            Coverage statistics\n",
        "        \"\"\"\n",
        "\n",
        "        vocab = set(self.wv.index_to_key)\n",
        "\n",
        "        total_words = 0\n",
        "        covered_words = 0\n",
        "        unknown_words = set()\n",
        "\n",
        "        for text in test_texts:\n",
        "            words = text.lower().split()\n",
        "            total_words += len(words)\n",
        "\n",
        "            for word in words:\n",
        "                if word in vocab:\n",
        "                    covered_words += 1\n",
        "                else:\n",
        "                    unknown_words.add(word)\n",
        "\n",
        "        coverage_ratio = covered_words / total_words if total_words > 0 else 0\n",
        "\n",
        "        print(f\"Vocabulary Coverage Analysis:\")\n",
        "        print(f\"  Total words in test: {total_words}\")\n",
        "        print(f\"  Covered words: {covered_words}\")\n",
        "        print(f\"  Coverage ratio: {coverage_ratio:.4f}\")\n",
        "        print(f\"  Unknown words: {len(unknown_words)}\")\n",
        "\n",
        "        return {\n",
        "            'coverage_ratio': coverage_ratio,\n",
        "            'unknown_words': list(unknown_words)[:20],  # Show first 20\n",
        "            'total_unknown': len(unknown_words)\n",
        "        }\n",
        "\n",
        "    def compare_with_baseline(self, baseline_model, test_words):\n",
        "        \"\"\"\n",
        "        Compare model performance with baseline model\n",
        "\n",
        "        Args:\n",
        "            baseline_model: Another Word2Vec model to compare against\n",
        "            test_words: List of words to test\n",
        "\n",
        "        Returns:\n",
        "            Comparison statistics\n",
        "        \"\"\"\n",
        "\n",
        "        common_words = []\n",
        "        for word in test_words:\n",
        "            if word in self.wv and word in baseline_model.wv:\n",
        "                common_words.append(word)\n",
        "\n",
        "        if len(common_words) < 10:\n",
        "            print(\"Warning: Too few common words for reliable comparison\")\n",
        "            return None\n",
        "\n",
        "        # Compare similarity patterns\n",
        "        similarities = []\n",
        "\n",
        "        for i, word1 in enumerate(common_words[:20]):  # Test subset\n",
        "            for word2 in common_words[i+1:21]:  # Avoid too many comparisons\n",
        "\n",
        "                sim1 = self.wv.similarity(word1, word2)\n",
        "                sim2 = baseline_model.wv.similarity(word1, word2)\n",
        "\n",
        "                similarities.append((sim1, sim2))\n",
        "\n",
        "        model_sims = [s for s in similarities]\n",
        "        baseline_sims = [s for s in similarities]\n",
        "\n",
        "        correlation, _ = spearmanr(model_sims, baseline_sims)\n",
        "\n",
        "        print(f\"Model Comparison:\")\n",
        "        print(f\"  Common vocabulary: {len(common_words)}\")\n",
        "        print(f\"  Similarity correlation: {correlation:.4f}\")\n",
        "\n",
        "        return correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV8R0_OsE2yy",
        "outputId": "efc8e205-cb77-41e3-8b4d-c34ec701645f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Too few valid word pairs for reliable evaluation\n",
            "Analogy Evaluation:\n",
            "Valid analogies: 4\n",
            "Correct predictions: 0\n",
            "Accuracy: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Example evaluation datasets\n",
        "word_similarity_pairs = [\n",
        "    ('king', 'queen', 8.5),\n",
        "    ('man', 'woman', 8.3),\n",
        "    ('car', 'automobile', 9.2),\n",
        "    ('computer', 'laptop', 7.8),\n",
        "    ('cat', 'dog', 6.1),\n",
        "    ('happy', 'sad', 2.1),\n",
        "]\n",
        "\n",
        "analogy_examples = [\n",
        "    ('king', 'queen', 'man', 'woman'),\n",
        "    ('paris', 'france', 'london', 'england'),\n",
        "    ('walking', 'walked', 'running', 'ran'),\n",
        "    ('good', 'better', 'bad', 'worse'),\n",
        "]\n",
        "\n",
        "# Usage example\n",
        "evaluator = Word2VecEvaluator(model)\n",
        "sim_score = evaluator.evaluate_word_similarity(word_similarity_pairs)\n",
        "analogy_score = evaluator.evaluate_analogies(analogy_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrbCvil3E4Sg",
        "outputId": "94d05b39-7d13-4757-a17c-97a4a6a6032e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most similar words to 'alice':\n",
            "herself: 0.991820752620697\n",
            "interesting: 0.9912858605384827\n",
            "so: 0.9912492632865906\n",
            "never: 0.9895081520080566\n",
            "nothing: 0.9894696474075317\n",
            "might: 0.9892017841339111\n",
            "very: 0.9891560673713684\n",
            "hear: 0.989135205745697\n",
            "now: 0.9891006946563721\n",
            "but: 0.9889737367630005\n"
          ]
        }
      ],
      "source": [
        "word = \"alice\"\n",
        "if word in model.wv:\n",
        "    similar_words = model.wv.most_similar(word, topn=10)\n",
        "    print(f\"Most similar words to '{word}':\")\n",
        "    for similar_word, similarity in similar_words:\n",
        "        print(f\"{similar_word}: {similarity}\")\n",
        "else:\n",
        "    print(\"Word is not in the vocabulary.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twEnf3p4E5LW",
        "outputId": "fa340ccb-fa36-4459-cbcd-fd246ca92ffb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.98991024"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.similarity('king', 'queen')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
